=== hostname ===
gadi-dgx-a100-0001.gadi.nci.org.au
=== PBS_JOBID ===
160698168.gadi-pbs
command line args [-m GRU4Rec -d ml-100k --config_files configs/ml-100k/ml100k_GRU4Rec.yaml] will not be used in RecBole
12 Feb 09:06    INFO  ['RecBole/run_recbole.py', '-m', 'GRU4Rec', '-d', 'ml-100k', '--config_files', 'configs/ml-100k/ml100k_GRU4Rec.yaml']
12 Feb 09:06    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /home/572/kd6504/TRACT/RecBole/recbole/config/../dataset_example/ml-100k
checkpoint_dir = outputs/gru4rec_ml100k
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [1, 5, 10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = {'inter': ['rating']}
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
kg_reverse_r = False
entity_kg_num_interval = None
relation_kg_num_interval = None
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 64
hidden_size = 128
num_layers = 1
dropout_prob = 0.3
loss_type = CE
numerical_features = []
discretization = None
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
12 Feb 09:06    INFO  ml-100k
The number of users: 944
Average actions of users: 105.28844114528101
The number of items: 1350
Average actions of items: 73.6004447739066
The number of inters: 99287
The sparsity of the dataset: 92.20911801632141%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
12 Feb 09:06    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
12 Feb 09:06    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
12 Feb 09:06    INFO  GRU4Rec(
  (item_embedding): Embedding(1350, 64, padding_idx=0)
  (emb_dropout): Dropout(p=0.3, inplace=False)
  (gru_layers): GRU(64, 128, bias=False, batch_first=True)
  (dense): Linear(in_features=128, out_features=64, bias=True)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 168384
/scratch/up63/kd6504/venvs/hopper-cu124/lib64/python3.11/site-packages/torch/nn/modules/rnn.py:1393: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)
  result = _VF.gru(
12 Feb 09:06    INFO  FLOPs: 4144064.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
12 Feb 09:06    INFO  epoch 0 training [time: 4.75s, train loss: 4801.6721]
12 Feb 09:06    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.051000]
12 Feb 09:06    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.053    hit@10 : 0.1135    hit@20 : 0.1866    ndcg@1 : 0.0127    ndcg@5 : 0.0315    ndcg@10 : 0.051    ndcg@20 : 0.0693    mrr@1 : 0.0127    mrr@5 : 0.0246    mrr@10 : 0.0326    mrr@20 : 0.0376
12 Feb 09:06    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:06    INFO  epoch 1 training [time: 4.32s, train loss: 4403.2556]
12 Feb 09:06    INFO  epoch 1 evaluating [time: 0.01s, valid_score: 0.053400]
12 Feb 09:06    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0604    hit@10 : 0.1209    hit@20 : 0.2057    ndcg@1 : 0.0085    ndcg@5 : 0.0339    ndcg@10 : 0.0534    ndcg@20 : 0.0749    mrr@1 : 0.0085    mrr@5 : 0.0253    mrr@10 : 0.0334    mrr@20 : 0.0393
12 Feb 09:06    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 2 training [time: 4.29s, train loss: 4333.2902]
12 Feb 09:07    INFO  epoch 2 evaluating [time: 0.01s, valid_score: 0.059300]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0679    hit@10 : 0.1188    hit@20 : 0.2142    ndcg@1 : 0.017    ndcg@5 : 0.0431    ndcg@10 : 0.0593    ndcg@20 : 0.0834    mrr@1 : 0.017    mrr@5 : 0.0349    mrr@10 : 0.0415    mrr@20 : 0.048
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 3 training [time: 4.29s, train loss: 4287.4347]
12 Feb 09:07    INFO  epoch 3 evaluating [time: 0.01s, valid_score: 0.061800]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0785    hit@10 : 0.1294    hit@20 : 0.211    ndcg@1 : 0.0159    ndcg@5 : 0.0457    ndcg@10 : 0.0618    ndcg@20 : 0.0823    mrr@1 : 0.0159    mrr@5 : 0.0352    mrr@10 : 0.0416    mrr@20 : 0.0471
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 4 training [time: 4.27s, train loss: 4251.2700]
12 Feb 09:07    INFO  epoch 4 evaluating [time: 0.01s, valid_score: 0.058700]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0732    hit@10 : 0.1241    hit@20 : 0.2365    ndcg@1 : 0.0127    ndcg@5 : 0.0427    ndcg@10 : 0.0587    ndcg@20 : 0.0872    mrr@1 : 0.0127    mrr@5 : 0.0328    mrr@10 : 0.0391    mrr@20 : 0.0469
12 Feb 09:07    INFO  epoch 5 training [time: 4.29s, train loss: 4221.3611]
12 Feb 09:07    INFO  epoch 5 evaluating [time: 0.01s, valid_score: 0.064900]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0657    hit@10 : 0.141    hit@20 : 0.2428    ndcg@1 : 0.0159    ndcg@5 : 0.0404    ndcg@10 : 0.0649    ndcg@20 : 0.0907    mrr@1 : 0.0159    mrr@5 : 0.0321    mrr@10 : 0.0424    mrr@20 : 0.0495
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 6 training [time: 4.29s, train loss: 4194.2969]
12 Feb 09:07    INFO  epoch 6 evaluating [time: 0.01s, valid_score: 0.065700]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0201    hit@5 : 0.0657    hit@10 : 0.1357    hit@20 : 0.2344    ndcg@1 : 0.0201    ndcg@5 : 0.0431    ndcg@10 : 0.0657    ndcg@20 : 0.0901    mrr@1 : 0.0201    mrr@5 : 0.0356    mrr@10 : 0.045    mrr@20 : 0.0514
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 7 training [time: 4.27s, train loss: 4169.5671]
12 Feb 09:07    INFO  epoch 7 evaluating [time: 0.01s, valid_score: 0.060700]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0657    hit@10 : 0.1326    hit@20 : 0.2418    ndcg@1 : 0.0159    ndcg@5 : 0.0392    ndcg@10 : 0.0607    ndcg@20 : 0.0883    mrr@1 : 0.0159    mrr@5 : 0.0307    mrr@10 : 0.0396    mrr@20 : 0.0471
12 Feb 09:07    INFO  epoch 8 training [time: 4.28s, train loss: 4146.5679]
12 Feb 09:07    INFO  epoch 8 evaluating [time: 0.01s, valid_score: 0.066100]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.071    hit@10 : 0.141    hit@20 : 0.2683    ndcg@1 : 0.017    ndcg@5 : 0.0439    ndcg@10 : 0.0661    ndcg@20 : 0.0981    mrr@1 : 0.017    mrr@5 : 0.035    mrr@10 : 0.044    mrr@20 : 0.0526
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 9 training [time: 4.28s, train loss: 4126.0878]
12 Feb 09:07    INFO  epoch 9 evaluating [time: 0.01s, valid_score: 0.065600]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0679    hit@10 : 0.141    hit@20 : 0.2534    ndcg@1 : 0.017    ndcg@5 : 0.0419    ndcg@10 : 0.0656    ndcg@20 : 0.0941    mrr@1 : 0.017    mrr@5 : 0.0335    mrr@10 : 0.0433    mrr@20 : 0.0511
12 Feb 09:07    INFO  epoch 10 training [time: 4.28s, train loss: 4105.8255]
12 Feb 09:07    INFO  epoch 10 evaluating [time: 0.01s, valid_score: 0.069900]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0191    hit@5 : 0.0827    hit@10 : 0.1463    hit@20 : 0.2428    ndcg@1 : 0.0191    ndcg@5 : 0.05    ndcg@10 : 0.0699    ndcg@20 : 0.0942    mrr@1 : 0.0191    mrr@5 : 0.0393    mrr@10 : 0.0472    mrr@20 : 0.0538
12 Feb 09:07    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:07    INFO  epoch 11 training [time: 4.30s, train loss: 4087.4329]
12 Feb 09:07    INFO  epoch 11 evaluating [time: 0.01s, valid_score: 0.069600]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0753    hit@10 : 0.1591    hit@20 : 0.2481    ndcg@1 : 0.0095    ndcg@5 : 0.0429    ndcg@10 : 0.0696    ndcg@20 : 0.0921    mrr@1 : 0.0095    mrr@5 : 0.0323    mrr@10 : 0.0431    mrr@20 : 0.0493
12 Feb 09:07    INFO  epoch 12 training [time: 4.30s, train loss: 4068.9450]
12 Feb 09:07    INFO  epoch 12 evaluating [time: 0.01s, valid_score: 0.065000]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0753    hit@10 : 0.1379    hit@20 : 0.2481    ndcg@1 : 0.017    ndcg@5 : 0.0451    ndcg@10 : 0.065    ndcg@20 : 0.0927    mrr@1 : 0.017    mrr@5 : 0.0353    mrr@10 : 0.0433    mrr@20 : 0.0508
12 Feb 09:07    INFO  epoch 13 training [time: 4.27s, train loss: 4050.6941]
12 Feb 09:07    INFO  epoch 13 evaluating [time: 0.01s, valid_score: 0.066500]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0201    hit@5 : 0.0742    hit@10 : 0.1389    hit@20 : 0.263    ndcg@1 : 0.0201    ndcg@5 : 0.0459    ndcg@10 : 0.0665    ndcg@20 : 0.0979    mrr@1 : 0.0201    mrr@5 : 0.0368    mrr@10 : 0.0452    mrr@20 : 0.0538
12 Feb 09:07    INFO  epoch 14 training [time: 4.27s, train loss: 4034.1612]
12 Feb 09:07    INFO  epoch 14 evaluating [time: 0.01s, valid_score: 0.066800]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0732    hit@10 : 0.1421    hit@20 : 0.2587    ndcg@1 : 0.017    ndcg@5 : 0.0448    ndcg@10 : 0.0668    ndcg@20 : 0.0962    mrr@1 : 0.017    mrr@5 : 0.0356    mrr@10 : 0.0445    mrr@20 : 0.0525
12 Feb 09:07    INFO  epoch 15 training [time: 4.28s, train loss: 4015.8238]
12 Feb 09:07    INFO  epoch 15 evaluating [time: 0.01s, valid_score: 0.063300]
12 Feb 09:07    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0732    hit@10 : 0.1357    hit@20 : 0.2524    ndcg@1 : 0.0148    ndcg@5 : 0.0432    ndcg@10 : 0.0633    ndcg@20 : 0.0927    mrr@1 : 0.0148    mrr@5 : 0.0335    mrr@10 : 0.0417    mrr@20 : 0.0497
12 Feb 09:08    INFO  epoch 16 training [time: 4.28s, train loss: 3999.8499]
12 Feb 09:08    INFO  epoch 16 evaluating [time: 0.01s, valid_score: 0.075300]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0201    hit@5 : 0.087    hit@10 : 0.1569    hit@20 : 0.2481    ndcg@1 : 0.0201    ndcg@5 : 0.0533    ndcg@10 : 0.0753    ndcg@20 : 0.0981    mrr@1 : 0.0201    mrr@5 : 0.0423    mrr@10 : 0.051    mrr@20 : 0.0572
12 Feb 09:08    INFO  Saving current: outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:08    INFO  epoch 17 training [time: 4.28s, train loss: 3983.1169]
12 Feb 09:08    INFO  epoch 17 evaluating [time: 0.01s, valid_score: 0.064000]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.0721    hit@10 : 0.1421    hit@20 : 0.2556    ndcg@1 : 0.0138    ndcg@5 : 0.0419    ndcg@10 : 0.064    ndcg@20 : 0.0926    mrr@1 : 0.0138    mrr@5 : 0.0321    mrr@10 : 0.041    mrr@20 : 0.0487
12 Feb 09:08    INFO  epoch 18 training [time: 4.27s, train loss: 3967.8775]
12 Feb 09:08    INFO  epoch 18 evaluating [time: 0.01s, valid_score: 0.069300]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0732    hit@10 : 0.1495    hit@20 : 0.2524    ndcg@1 : 0.0159    ndcg@5 : 0.0451    ndcg@10 : 0.0693    ndcg@20 : 0.0949    mrr@1 : 0.0159    mrr@5 : 0.0359    mrr@10 : 0.0456    mrr@20 : 0.0524
12 Feb 09:08    INFO  epoch 19 training [time: 4.27s, train loss: 3953.2641]
12 Feb 09:08    INFO  epoch 19 evaluating [time: 0.01s, valid_score: 0.068400]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0742    hit@10 : 0.1485    hit@20 : 0.2609    ndcg@1 : 0.017    ndcg@5 : 0.0449    ndcg@10 : 0.0684    ndcg@20 : 0.0965    mrr@1 : 0.017    mrr@5 : 0.0354    mrr@10 : 0.0448    mrr@20 : 0.0523
12 Feb 09:08    INFO  epoch 20 training [time: 4.29s, train loss: 3939.1469]
12 Feb 09:08    INFO  epoch 20 evaluating [time: 0.01s, valid_score: 0.071800]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0223    hit@5 : 0.0742    hit@10 : 0.1516    hit@20 : 0.2545    ndcg@1 : 0.0223    ndcg@5 : 0.0473    ndcg@10 : 0.0718    ndcg@20 : 0.0979    mrr@1 : 0.0223    mrr@5 : 0.0385    mrr@10 : 0.0484    mrr@20 : 0.0556
12 Feb 09:08    INFO  epoch 21 training [time: 4.28s, train loss: 3925.5817]
12 Feb 09:08    INFO  epoch 21 evaluating [time: 0.01s, valid_score: 0.070800]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0212    hit@5 : 0.0795    hit@10 : 0.1432    hit@20 : 0.2534    ndcg@1 : 0.0212    ndcg@5 : 0.0505    ndcg@10 : 0.0708    ndcg@20 : 0.0985    mrr@1 : 0.0212    mrr@5 : 0.041    mrr@10 : 0.0492    mrr@20 : 0.0568
12 Feb 09:08    INFO  epoch 22 training [time: 4.27s, train loss: 3911.5919]
12 Feb 09:08    INFO  epoch 22 evaluating [time: 0.01s, valid_score: 0.063200]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.07    hit@10 : 0.1357    hit@20 : 0.2471    ndcg@1 : 0.017    ndcg@5 : 0.0423    ndcg@10 : 0.0632    ndcg@20 : 0.0915    mrr@1 : 0.017    mrr@5 : 0.0333    mrr@10 : 0.0418    mrr@20 : 0.0496
12 Feb 09:08    INFO  epoch 23 training [time: 4.28s, train loss: 3898.3321]
12 Feb 09:08    INFO  epoch 23 evaluating [time: 0.01s, valid_score: 0.065800]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.0859    hit@10 : 0.1432    hit@20 : 0.2609    ndcg@1 : 0.0138    ndcg@5 : 0.0476    ndcg@10 : 0.0658    ndcg@20 : 0.0955    mrr@1 : 0.0138    mrr@5 : 0.0354    mrr@10 : 0.0426    mrr@20 : 0.0507
12 Feb 09:08    INFO  epoch 24 training [time: 4.27s, train loss: 3885.6017]
12 Feb 09:08    INFO  epoch 24 evaluating [time: 0.01s, valid_score: 0.062400]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0679    hit@10 : 0.1273    hit@20 : 0.2418    ndcg@1 : 0.017    ndcg@5 : 0.0434    ndcg@10 : 0.0624    ndcg@20 : 0.0912    mrr@1 : 0.017    mrr@5 : 0.0353    mrr@10 : 0.043    mrr@20 : 0.0509
12 Feb 09:08    INFO  epoch 25 training [time: 4.27s, train loss: 3870.7178]
12 Feb 09:08    INFO  epoch 25 evaluating [time: 0.01s, valid_score: 0.063800]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.071    hit@10 : 0.1368    hit@20 : 0.2503    ndcg@1 : 0.0148    ndcg@5 : 0.0428    ndcg@10 : 0.0638    ndcg@20 : 0.0924    mrr@1 : 0.0148    mrr@5 : 0.0336    mrr@10 : 0.0421    mrr@20 : 0.0499
12 Feb 09:08    INFO  epoch 26 training [time: 4.27s, train loss: 3858.6200]
12 Feb 09:08    INFO  epoch 26 evaluating [time: 0.01s, valid_score: 0.063100]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0806    hit@10 : 0.1326    hit@20 : 0.245    ndcg@1 : 0.0148    ndcg@5 : 0.0465    ndcg@10 : 0.0631    ndcg@20 : 0.0913    mrr@1 : 0.0148    mrr@5 : 0.0355    mrr@10 : 0.0422    mrr@20 : 0.0498
12 Feb 09:08    INFO  epoch 27 training [time: 4.26s, train loss: 3848.3345]
12 Feb 09:08    INFO  epoch 27 evaluating [time: 0.01s, valid_score: 0.067800]
12 Feb 09:08    INFO  valid result: 
hit@1 : 0.0244    hit@5 : 0.07    hit@10 : 0.1347    hit@20 : 0.2428    ndcg@1 : 0.0244    ndcg@5 : 0.0469    ndcg@10 : 0.0678    ndcg@20 : 0.095    mrr@1 : 0.0244    mrr@5 : 0.0393    mrr@10 : 0.048    mrr@20 : 0.0554
12 Feb 09:08    INFO  Finished training, best eval result in epoch 16
12 Feb 09:08    INFO  Loading model structure and parameters from outputs/gru4rec_ml100k/GRU4Rec-Feb-12-2026_09-06-45.pth
12 Feb 09:08    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      1.20 %      |
+-------------+------------------+
| GPU         |  0.57 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.32 G/2015.66 G |
+-------------+------------------+
12 Feb 09:08    INFO  best valid : OrderedDict([('hit@1', 0.0201), ('hit@5', 0.087), ('hit@10', 0.1569), ('hit@20', 0.2481), ('ndcg@1', 0.0201), ('ndcg@5', 0.0533), ('ndcg@10', 0.0753), ('ndcg@20', 0.0981), ('mrr@1', 0.0201), ('mrr@5', 0.0423), ('mrr@10', 0.051), ('mrr@20', 0.0572)])
12 Feb 09:08    INFO  test result: OrderedDict([('hit@1', 0.017), ('hit@5', 0.0806), ('hit@10', 0.1304), ('hit@20', 0.2259), ('ndcg@1', 0.017), ('ndcg@5', 0.0493), ('ndcg@10', 0.065), ('ndcg@20', 0.0891), ('mrr@1', 0.017), ('mrr@5', 0.039), ('mrr@10', 0.0453), ('mrr@20', 0.0518)])
Job completed.

======================================================================================
                  Resource Usage on 2026-02-12 09:08:53:
   Job Id:             160698168.gadi-pbs
   Project:            up63
   Exit Status:        0
   Service Units:      2.72
   NCPUs Requested:    16                  CPU Time Used: 00:02:10        
   Memory Requested:   16.0GB                Memory Used: 1.23GB          
   NGPUs Requested:    1                 GPU Utilisation: 28%             
                                         GPU Memory Used: 1.07GB          
   Walltime Requested: 04:00:00            Walltime Used: 00:02:16        
   JobFS Requested:    100.0MB                JobFS Used: 5.03KB          
======================================================================================
