command line args [-m pswrecv4h -d ml-100k --config_files configs/ml-100k/ml100k_pswrecv4h.yaml] will not be used in RecBole
12 Feb 09:36    INFO  ['RecBole/run_recbole.py', '-m', 'pswrecv4h', '-d', 'ml-100k', '--config_files', 'configs/ml-100k/ml100k_pswrecv4h.yaml']
12 Feb 09:36    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /home/572/kd6504/TRACT/RecBole/recbole/config/../dataset_example/ml-100k
checkpoint_dir = outputs/pswrecv4h_ml100k
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [1, 5, 10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = {'inter': ['rating']}
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
kg_reverse_r = False
entity_kg_num_interval = None
relation_kg_num_interval = None
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
numerical_features = []
discretization = None
MODEL_TYPE = ModelType.SEQUENTIAL
loss_type = CE
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
n_bands = 4
band_kernel_sizes = [3, 7, 15, 31]
band_dilations = [1, 2, 4, 8]
phase_bias_scale = 0.1
phase_aux = True
phase_aux_weight = 0.05
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
12 Feb 09:36    INFO  ml-100k
The number of users: 944
Average actions of users: 105.28844114528101
The number of items: 1350
Average actions of items: 73.6004447739066
The number of inters: 99287
The sparsity of the dataset: 92.20911801632141%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
12 Feb 09:36    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
12 Feb 09:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
12 Feb 09:36    INFO  pswrecv4h(
  (item_embedding): Embedding(1350, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (phase_filter): LocalPhaseFilterBankV4H(
    (real_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(2,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), dilation=(4,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), dilation=(8,), groups=64, bias=False)
    )
    (imag_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(2,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), dilation=(4,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), dilation=(8,), groups=64, bias=False)
    )
  )
  (encoder): PSWEncoderV4H(
    (layers): ModuleList(
      (0-1): 2 x PSWBlockV4H(
        (attn): PhaseSyncAttentionV4H(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        )
        (ffn): FeedForwardV4H(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 196884
12 Feb 09:36    INFO  FLOPs: 5312064.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
12 Feb 09:37    INFO  epoch 0 training [time: 52.46s, train loss: 4732.5101]
12 Feb 09:37    INFO  epoch 0 evaluating [time: 0.06s, valid_score: 0.047900]
12 Feb 09:37    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0541    hit@10 : 0.1039    hit@20 : 0.1803    ndcg@1 : 0.0095    ndcg@5 : 0.0318    ndcg@10 : 0.0479    ndcg@20 : 0.0671    mrr@1 : 0.0095    mrr@5 : 0.0245    mrr@10 : 0.0312    mrr@20 : 0.0364
12 Feb 09:37    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:38    INFO  epoch 1 training [time: 52.20s, train loss: 4439.0517]
12 Feb 09:38    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.050500]
12 Feb 09:38    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0668    hit@10 : 0.1103    hit@20 : 0.2047    ndcg@1 : 0.0085    ndcg@5 : 0.0365    ndcg@10 : 0.0505    ndcg@20 : 0.0743    mrr@1 : 0.0085    mrr@5 : 0.0267    mrr@10 : 0.0324    mrr@20 : 0.0389
12 Feb 09:38    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:39    INFO  epoch 2 training [time: 52.24s, train loss: 4379.9200]
12 Feb 09:39    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 0.060800]
12 Feb 09:39    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.071    hit@10 : 0.1315    hit@20 : 0.2259    ndcg@1 : 0.0138    ndcg@5 : 0.0417    ndcg@10 : 0.0608    ndcg@20 : 0.0841    mrr@1 : 0.0138    mrr@5 : 0.0322    mrr@10 : 0.0398    mrr@20 : 0.0459
12 Feb 09:39    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:40    INFO  epoch 3 training [time: 52.06s, train loss: 4340.4901]
12 Feb 09:40    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 0.062500]
12 Feb 09:40    INFO  valid result: 
hit@1 : 0.0191    hit@5 : 0.0764    hit@10 : 0.123    hit@20 : 0.2248    ndcg@1 : 0.0191    ndcg@5 : 0.0475    ndcg@10 : 0.0625    ndcg@20 : 0.088    mrr@1 : 0.0191    mrr@5 : 0.0381    mrr@10 : 0.0442    mrr@20 : 0.0511
12 Feb 09:40    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:41    INFO  epoch 4 training [time: 52.14s, train loss: 4316.7832]
12 Feb 09:41    INFO  epoch 4 evaluating [time: 0.02s, valid_score: 0.057800]
12 Feb 09:41    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0689    hit@10 : 0.1315    hit@20 : 0.2333    ndcg@1 : 0.0085    ndcg@5 : 0.0378    ndcg@10 : 0.0578    ndcg@20 : 0.0832    mrr@1 : 0.0085    mrr@5 : 0.0277    mrr@10 : 0.0358    mrr@20 : 0.0426
12 Feb 09:42    INFO  epoch 5 training [time: 52.22s, train loss: 4295.4771]
12 Feb 09:42    INFO  epoch 5 evaluating [time: 0.02s, valid_score: 0.065400]
12 Feb 09:42    INFO  valid result: 
hit@1 : 0.018    hit@5 : 0.07    hit@10 : 0.1389    hit@20 : 0.2407    ndcg@1 : 0.018    ndcg@5 : 0.0432    ndcg@10 : 0.0654    ndcg@20 : 0.0911    mrr@1 : 0.018    mrr@5 : 0.0345    mrr@10 : 0.0436    mrr@20 : 0.0507
12 Feb 09:42    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:42    INFO  epoch 6 training [time: 52.23s, train loss: 4279.2942]
12 Feb 09:42    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 0.058400]
12 Feb 09:42    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0732    hit@10 : 0.1304    hit@20 : 0.2301    ndcg@1 : 0.0085    ndcg@5 : 0.0401    ndcg@10 : 0.0584    ndcg@20 : 0.0834    mrr@1 : 0.0085    mrr@5 : 0.0294    mrr@10 : 0.0368    mrr@20 : 0.0436
12 Feb 09:43    INFO  epoch 7 training [time: 52.28s, train loss: 4266.8820]
12 Feb 09:43    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.056400]
12 Feb 09:43    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0636    hit@10 : 0.1241    hit@20 : 0.2238    ndcg@1 : 0.0106    ndcg@5 : 0.0373    ndcg@10 : 0.0564    ndcg@20 : 0.0814    mrr@1 : 0.0106    mrr@5 : 0.0287    mrr@10 : 0.0363    mrr@20 : 0.043
12 Feb 09:44    INFO  epoch 8 training [time: 52.30s, train loss: 4256.6873]
12 Feb 09:44    INFO  epoch 8 evaluating [time: 0.02s, valid_score: 0.062600]
12 Feb 09:44    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0785    hit@10 : 0.1347    hit@20 : 0.2354    ndcg@1 : 0.0117    ndcg@5 : 0.0448    ndcg@10 : 0.0626    ndcg@20 : 0.0879    mrr@1 : 0.0117    mrr@5 : 0.0338    mrr@10 : 0.0409    mrr@20 : 0.0478
12 Feb 09:45    INFO  epoch 9 training [time: 52.26s, train loss: 4246.8346]
12 Feb 09:45    INFO  epoch 9 evaluating [time: 0.02s, valid_score: 0.065900]
12 Feb 09:45    INFO  valid result: 
hit@1 : 0.018    hit@5 : 0.0764    hit@10 : 0.1357    hit@20 : 0.245    ndcg@1 : 0.018    ndcg@5 : 0.0469    ndcg@10 : 0.0659    ndcg@20 : 0.0932    mrr@1 : 0.018    mrr@5 : 0.0373    mrr@10 : 0.0451    mrr@20 : 0.0524
12 Feb 09:45    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:46    INFO  epoch 10 training [time: 52.19s, train loss: 4239.0104]
12 Feb 09:46    INFO  epoch 10 evaluating [time: 0.02s, valid_score: 0.067300]
12 Feb 09:46    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0679    hit@10 : 0.1506    hit@20 : 0.2545    ndcg@1 : 0.0148    ndcg@5 : 0.041    ndcg@10 : 0.0673    ndcg@20 : 0.0935    mrr@1 : 0.0148    mrr@5 : 0.0323    mrr@10 : 0.0429    mrr@20 : 0.05
12 Feb 09:46    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:47    INFO  epoch 11 training [time: 51.81s, train loss: 4229.9523]
12 Feb 09:47    INFO  epoch 11 evaluating [time: 0.02s, valid_score: 0.068100]
12 Feb 09:47    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0817    hit@10 : 0.141    hit@20 : 0.2566    ndcg@1 : 0.017    ndcg@5 : 0.0491    ndcg@10 : 0.0681    ndcg@20 : 0.0971    mrr@1 : 0.017    mrr@5 : 0.0384    mrr@10 : 0.0462    mrr@20 : 0.054
12 Feb 09:47    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:48    INFO  epoch 12 training [time: 51.17s, train loss: 4224.0309]
12 Feb 09:48    INFO  epoch 12 evaluating [time: 0.02s, valid_score: 0.070600]
12 Feb 09:48    INFO  valid result: 
hit@1 : 0.018    hit@5 : 0.0838    hit@10 : 0.1495    hit@20 : 0.2428    ndcg@1 : 0.018    ndcg@5 : 0.0493    ndcg@10 : 0.0706    ndcg@20 : 0.0939    mrr@1 : 0.018    mrr@5 : 0.0382    mrr@10 : 0.047    mrr@20 : 0.0533
12 Feb 09:48    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:49    INFO  epoch 13 training [time: 50.86s, train loss: 4217.7466]
12 Feb 09:49    INFO  epoch 13 evaluating [time: 0.02s, valid_score: 0.072800]
12 Feb 09:49    INFO  valid result: 
hit@1 : 0.0201    hit@5 : 0.0859    hit@10 : 0.1495    hit@20 : 0.2609    ndcg@1 : 0.0201    ndcg@5 : 0.0524    ndcg@10 : 0.0728    ndcg@20 : 0.1007    mrr@1 : 0.0201    mrr@5 : 0.0416    mrr@10 : 0.0498    mrr@20 : 0.0573
12 Feb 09:49    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:49    INFO  epoch 14 training [time: 51.02s, train loss: 4212.1793]
12 Feb 09:49    INFO  epoch 14 evaluating [time: 0.02s, valid_score: 0.072800]
12 Feb 09:49    INFO  valid result: 
hit@1 : 0.0233    hit@5 : 0.0891    hit@10 : 0.1474    hit@20 : 0.2556    ndcg@1 : 0.0233    ndcg@5 : 0.0543    ndcg@10 : 0.0728    ndcg@20 : 0.1    mrr@1 : 0.0233    mrr@5 : 0.0431    mrr@10 : 0.0505    mrr@20 : 0.0579
12 Feb 09:49    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:50    INFO  epoch 15 training [time: 50.86s, train loss: 4208.3356]
12 Feb 09:50    INFO  epoch 15 evaluating [time: 0.02s, valid_score: 0.074200]
12 Feb 09:50    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0848    hit@10 : 0.1601    hit@20 : 0.2524    ndcg@1 : 0.017    ndcg@5 : 0.0502    ndcg@10 : 0.0742    ndcg@20 : 0.0974    mrr@1 : 0.017    mrr@5 : 0.039    mrr@10 : 0.0487    mrr@20 : 0.0549
12 Feb 09:50    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:51    INFO  epoch 16 training [time: 50.84s, train loss: 4203.5753]
12 Feb 09:51    INFO  epoch 16 evaluating [time: 0.02s, valid_score: 0.074100]
12 Feb 09:51    INFO  valid result: 
hit@1 : 0.0212    hit@5 : 0.0891    hit@10 : 0.1485    hit@20 : 0.2577    ndcg@1 : 0.0212    ndcg@5 : 0.0549    ndcg@10 : 0.0741    ndcg@20 : 0.1016    mrr@1 : 0.0212    mrr@5 : 0.0438    mrr@10 : 0.0517    mrr@20 : 0.0592
12 Feb 09:52    INFO  epoch 17 training [time: 50.89s, train loss: 4199.3222]
12 Feb 09:52    INFO  epoch 17 evaluating [time: 0.02s, valid_score: 0.074700]
12 Feb 09:52    INFO  valid result: 
hit@1 : 0.0212    hit@5 : 0.0795    hit@10 : 0.1612    hit@20 : 0.2587    ndcg@1 : 0.0212    ndcg@5 : 0.0486    ndcg@10 : 0.0747    ndcg@20 : 0.0993    mrr@1 : 0.0212    mrr@5 : 0.0387    mrr@10 : 0.0493    mrr@20 : 0.056
12 Feb 09:52    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:53    INFO  epoch 18 training [time: 50.89s, train loss: 4194.6023]
12 Feb 09:53    INFO  epoch 18 evaluating [time: 0.02s, valid_score: 0.071200]
12 Feb 09:53    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0742    hit@10 : 0.1591    hit@20 : 0.2566    ndcg@1 : 0.0148    ndcg@5 : 0.0441    ndcg@10 : 0.0712    ndcg@20 : 0.0953    mrr@1 : 0.0148    mrr@5 : 0.0342    mrr@10 : 0.0452    mrr@20 : 0.0516
12 Feb 09:54    INFO  epoch 19 training [time: 50.87s, train loss: 4192.5311]
12 Feb 09:54    INFO  epoch 19 evaluating [time: 0.02s, valid_score: 0.067300]
12 Feb 09:54    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0785    hit@10 : 0.1442    hit@20 : 0.2651    ndcg@1 : 0.0148    ndcg@5 : 0.0461    ndcg@10 : 0.0673    ndcg@20 : 0.0976    mrr@1 : 0.0148    mrr@5 : 0.0356    mrr@10 : 0.0443    mrr@20 : 0.0525
12 Feb 09:54    INFO  epoch 20 training [time: 50.84s, train loss: 4188.8408]
12 Feb 09:54    INFO  epoch 20 evaluating [time: 0.02s, valid_score: 0.073000]
12 Feb 09:54    INFO  valid result: 
hit@1 : 0.0201    hit@5 : 0.0785    hit@10 : 0.1538    hit@20 : 0.2524    ndcg@1 : 0.0201    ndcg@5 : 0.0491    ndcg@10 : 0.073    ndcg@20 : 0.098    mrr@1 : 0.0201    mrr@5 : 0.0395    mrr@10 : 0.0492    mrr@20 : 0.0561
12 Feb 09:55    INFO  epoch 21 training [time: 50.87s, train loss: 4185.8262]
12 Feb 09:55    INFO  epoch 21 evaluating [time: 0.02s, valid_score: 0.071300]
12 Feb 09:55    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0827    hit@10 : 0.1527    hit@20 : 0.2672    ndcg@1 : 0.0159    ndcg@5 : 0.0487    ndcg@10 : 0.0713    ndcg@20 : 0.1002    mrr@1 : 0.0159    mrr@5 : 0.0376    mrr@10 : 0.0469    mrr@20 : 0.0548
12 Feb 09:56    INFO  epoch 22 training [time: 50.87s, train loss: 4182.5940]
12 Feb 09:56    INFO  epoch 22 evaluating [time: 0.02s, valid_score: 0.072500]
12 Feb 09:56    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0859    hit@10 : 0.158    hit@20 : 0.2715    ndcg@1 : 0.0159    ndcg@5 : 0.0494    ndcg@10 : 0.0725    ndcg@20 : 0.101    mrr@1 : 0.0159    mrr@5 : 0.0376    mrr@10 : 0.047    mrr@20 : 0.0547
12 Feb 09:57    INFO  epoch 23 training [time: 51.02s, train loss: 4178.3405]
12 Feb 09:57    INFO  epoch 23 evaluating [time: 0.02s, valid_score: 0.075500]
12 Feb 09:57    INFO  valid result: 
hit@1 : 0.018    hit@5 : 0.0817    hit@10 : 0.1612    hit@20 : 0.28    ndcg@1 : 0.018    ndcg@5 : 0.0499    ndcg@10 : 0.0755    ndcg@20 : 0.1054    mrr@1 : 0.018    mrr@5 : 0.0396    mrr@10 : 0.05    mrr@20 : 0.0582
12 Feb 09:57    INFO  Saving current: outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 09:58    INFO  epoch 24 training [time: 50.93s, train loss: 4176.7016]
12 Feb 09:58    INFO  epoch 24 evaluating [time: 0.02s, valid_score: 0.067900]
12 Feb 09:58    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.0732    hit@10 : 0.1485    hit@20 : 0.2651    ndcg@1 : 0.0138    ndcg@5 : 0.0437    ndcg@10 : 0.0679    ndcg@20 : 0.0972    mrr@1 : 0.0138    mrr@5 : 0.0341    mrr@10 : 0.0439    mrr@20 : 0.0519
12 Feb 09:59    INFO  epoch 25 training [time: 50.77s, train loss: 4173.9516]
12 Feb 09:59    INFO  epoch 25 evaluating [time: 0.02s, valid_score: 0.071600]
12 Feb 09:59    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.088    hit@10 : 0.1559    hit@20 : 0.2577    ndcg@1 : 0.0127    ndcg@5 : 0.0496    ndcg@10 : 0.0716    ndcg@20 : 0.097    mrr@1 : 0.0127    mrr@5 : 0.0371    mrr@10 : 0.0462    mrr@20 : 0.053
12 Feb 10:00    INFO  epoch 26 training [time: 50.80s, train loss: 4172.4607]
12 Feb 10:00    INFO  epoch 26 evaluating [time: 0.02s, valid_score: 0.073000]
12 Feb 10:00    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.088    hit@10 : 0.158    hit@20 : 0.2662    ndcg@1 : 0.0148    ndcg@5 : 0.0506    ndcg@10 : 0.073    ndcg@20 : 0.1005    mrr@1 : 0.0148    mrr@5 : 0.0384    mrr@10 : 0.0475    mrr@20 : 0.0551
12 Feb 10:00    INFO  epoch 27 training [time: 51.01s, train loss: 4169.1764]
12 Feb 10:00    INFO  epoch 27 evaluating [time: 0.02s, valid_score: 0.072800]
12 Feb 10:00    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0838    hit@10 : 0.1654    hit@20 : 0.2619    ndcg@1 : 0.0127    ndcg@5 : 0.0467    ndcg@10 : 0.0728    ndcg@20 : 0.097    mrr@1 : 0.0127    mrr@5 : 0.0347    mrr@10 : 0.0453    mrr@20 : 0.0518
12 Feb 10:01    INFO  epoch 28 training [time: 50.85s, train loss: 4167.9579]
12 Feb 10:01    INFO  epoch 28 evaluating [time: 0.02s, valid_score: 0.068500]
12 Feb 10:01    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0817    hit@10 : 0.1538    hit@20 : 0.2577    ndcg@1 : 0.0117    ndcg@5 : 0.045    ndcg@10 : 0.0685    ndcg@20 : 0.0946    mrr@1 : 0.0117    mrr@5 : 0.0332    mrr@10 : 0.043    mrr@20 : 0.0501
12 Feb 10:02    INFO  epoch 29 training [time: 50.84s, train loss: 4164.8754]
12 Feb 10:02    INFO  epoch 29 evaluating [time: 0.02s, valid_score: 0.072100]
12 Feb 10:02    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.0848    hit@10 : 0.158    hit@20 : 0.2556    ndcg@1 : 0.0138    ndcg@5 : 0.0486    ndcg@10 : 0.0721    ndcg@20 : 0.0964    mrr@1 : 0.0138    mrr@5 : 0.0368    mrr@10 : 0.0464    mrr@20 : 0.0529
12 Feb 10:03    INFO  epoch 30 training [time: 50.91s, train loss: 4164.1901]
12 Feb 10:03    INFO  epoch 30 evaluating [time: 0.02s, valid_score: 0.070200]
12 Feb 10:03    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0827    hit@10 : 0.1569    hit@20 : 0.2662    ndcg@1 : 0.0127    ndcg@5 : 0.0466    ndcg@10 : 0.0702    ndcg@20 : 0.0976    mrr@1 : 0.0127    mrr@5 : 0.0349    mrr@10 : 0.0444    mrr@20 : 0.0518
12 Feb 10:04    INFO  epoch 31 training [time: 50.83s, train loss: 4161.5501]
12 Feb 10:04    INFO  epoch 31 evaluating [time: 0.02s, valid_score: 0.067100]
12 Feb 10:04    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0817    hit@10 : 0.1495    hit@20 : 0.263    ndcg@1 : 0.0095    ndcg@5 : 0.045    ndcg@10 : 0.0671    ndcg@20 : 0.0957    mrr@1 : 0.0095    mrr@5 : 0.033    mrr@10 : 0.0423    mrr@20 : 0.05
12 Feb 10:05    INFO  epoch 32 training [time: 50.95s, train loss: 4155.5569]
12 Feb 10:05    INFO  epoch 32 evaluating [time: 0.02s, valid_score: 0.070500]
12 Feb 10:05    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0753    hit@10 : 0.1612    hit@20 : 0.2545    ndcg@1 : 0.0127    ndcg@5 : 0.043    ndcg@10 : 0.0705    ndcg@20 : 0.0941    mrr@1 : 0.0127    mrr@5 : 0.0325    mrr@10 : 0.0437    mrr@20 : 0.0503
12 Feb 10:05    INFO  epoch 33 training [time: 50.86s, train loss: 4156.3644]
12 Feb 10:05    INFO  epoch 33 evaluating [time: 0.01s, valid_score: 0.067100]
12 Feb 10:05    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0753    hit@10 : 0.1506    hit@20 : 0.2609    ndcg@1 : 0.0117    ndcg@5 : 0.0429    ndcg@10 : 0.0671    ndcg@20 : 0.0945    mrr@1 : 0.0117    mrr@5 : 0.0324    mrr@10 : 0.0423    mrr@20 : 0.0496
12 Feb 10:06    INFO  epoch 34 training [time: 50.81s, train loss: 4155.6973]
12 Feb 10:06    INFO  epoch 34 evaluating [time: 0.02s, valid_score: 0.066200]
12 Feb 10:06    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0753    hit@10 : 0.1474    hit@20 : 0.263    ndcg@1 : 0.0117    ndcg@5 : 0.043    ndcg@10 : 0.0662    ndcg@20 : 0.0954    mrr@1 : 0.0117    mrr@5 : 0.0325    mrr@10 : 0.042    mrr@20 : 0.05
12 Feb 10:06    INFO  Finished training, best eval result in epoch 23
12 Feb 10:06    INFO  Loading model structure and parameters from outputs/pswrecv4h_ml100k/pswrecv4h-Feb-12-2026_09-36-49.pth
12 Feb 10:06    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      0.80 %      |
+-------------+------------------+
| GPU         |  0.50 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.42 G/2015.66 G |
+-------------+------------------+
12 Feb 10:06    INFO  best valid : OrderedDict([('hit@1', 0.018), ('hit@5', 0.0817), ('hit@10', 0.1612), ('hit@20', 0.28), ('ndcg@1', 0.018), ('ndcg@5', 0.0499), ('ndcg@10', 0.0755), ('ndcg@20', 0.1054), ('mrr@1', 0.018), ('mrr@5', 0.0396), ('mrr@10', 0.05), ('mrr@20', 0.0582)])
12 Feb 10:06    INFO  test result: OrderedDict([('hit@1', 0.0127), ('hit@5', 0.0774), ('hit@10', 0.1251), ('hit@20', 0.2344), ('ndcg@1', 0.0127), ('ndcg@5', 0.0462), ('ndcg@10', 0.0613), ('ndcg@20', 0.0888), ('mrr@1', 0.0127), ('mrr@5', 0.0359), ('mrr@10', 0.0419), ('mrr@20', 0.0494)])
