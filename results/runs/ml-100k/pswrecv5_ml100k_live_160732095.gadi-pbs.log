command line args [-m pswrecv5 -d ml-100k --config_files configs/ml-100k/ml100k_pswrecv5.yaml] will not be used in RecBole
12 Feb 13:36    INFO  ['RecBole/run_recbole.py', '-m', 'pswrecv5', '-d', 'ml-100k', '--config_files', 'configs/ml-100k/ml100k_pswrecv5.yaml']
12 Feb 13:36    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /home/572/kd6504/TRACT/RecBole/recbole/config/../dataset_example/ml-100k
checkpoint_dir = outputs/pswrecv5_ml100k
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [1, 5, 10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = {'inter': ['rating']}
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
kg_reverse_r = False
entity_kg_num_interval = None
relation_kg_num_interval = None
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
n_bands = 4
band_kernel_sizes = [3, 7, 15, 31]
band_dilations = [1, 2, 4, 8]
phase_bias_scale = 0.1
phase_gate_scale = 1.0
phase_aux = True
phase_aux_weight = 0.05
numerical_features = []
discretization = None
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
12 Feb 13:36    INFO  ml-100k
The number of users: 944
Average actions of users: 105.28844114528101
The number of items: 1350
Average actions of items: 73.6004447739066
The number of inters: 99287
The sparsity of the dataset: 92.20911801632141%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
12 Feb 13:36    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
12 Feb 13:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
12 Feb 13:36    INFO  pswrecv5(
  (item_embedding): Embedding(1350, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (phase_filter): LocalPhaseFilterBankV5(
    (real_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(2,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), dilation=(4,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), dilation=(8,), groups=64, bias=False)
    )
    (imag_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(2,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), dilation=(4,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), dilation=(8,), groups=64, bias=False)
    )
  )
  (encoder): PSWEncoderV5(
    (layers): ModuleList(
      (0-1): 2 x PSWBlockV5(
        (attn): PhaseSyncAttentionV5(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        )
        (ffn): FeedForwardV5(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 196886.0
12 Feb 13:36    INFO  FLOPs: 5312064.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
12 Feb 13:37    INFO  epoch 0 training [time: 55.01s, train loss: 4730.9904]
12 Feb 13:37    INFO  epoch 0 evaluating [time: 0.06s, valid_score: 0.051700]
12 Feb 13:37    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0615    hit@10 : 0.1135    hit@20 : 0.1856    ndcg@1 : 0.0117    ndcg@5 : 0.0353    ndcg@10 : 0.0517    ndcg@20 : 0.0696    mrr@1 : 0.0117    mrr@5 : 0.0269    mrr@10 : 0.0334    mrr@20 : 0.0382
12 Feb 13:37    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:38    INFO  epoch 1 training [time: 54.51s, train loss: 4435.6801]
12 Feb 13:38    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.053100]
12 Feb 13:38    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0615    hit@10 : 0.1166    hit@20 : 0.2185    ndcg@1 : 0.0085    ndcg@5 : 0.035    ndcg@10 : 0.0531    ndcg@20 : 0.0786    mrr@1 : 0.0085    mrr@5 : 0.0264    mrr@10 : 0.0339    mrr@20 : 0.0409
12 Feb 13:38    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:39    INFO  epoch 2 training [time: 54.89s, train loss: 4374.7590]
12 Feb 13:39    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 0.061700]
12 Feb 13:39    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0742    hit@10 : 0.1326    hit@20 : 0.2195    ndcg@1 : 0.0148    ndcg@5 : 0.0432    ndcg@10 : 0.0617    ndcg@20 : 0.0834    mrr@1 : 0.0148    mrr@5 : 0.0331    mrr@10 : 0.0406    mrr@20 : 0.0464
12 Feb 13:39    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:40    INFO  epoch 3 training [time: 54.44s, train loss: 4337.7440]
12 Feb 13:40    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 0.063300]
12 Feb 13:40    INFO  valid result: 
hit@1 : 0.0191    hit@5 : 0.07    hit@10 : 0.1273    hit@20 : 0.2248    ndcg@1 : 0.0191    ndcg@5 : 0.0446    ndcg@10 : 0.0633    ndcg@20 : 0.0876    mrr@1 : 0.0191    mrr@5 : 0.0363    mrr@10 : 0.0442    mrr@20 : 0.0506
12 Feb 13:40    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:41    INFO  epoch 4 training [time: 54.46s, train loss: 4314.0845]
12 Feb 13:41    INFO  epoch 4 evaluating [time: 0.02s, valid_score: 0.057800]
12 Feb 13:41    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0679    hit@10 : 0.1273    hit@20 : 0.228    ndcg@1 : 0.0106    ndcg@5 : 0.0385    ndcg@10 : 0.0578    ndcg@20 : 0.083    mrr@1 : 0.0106    mrr@5 : 0.029    mrr@10 : 0.037    mrr@20 : 0.0438
12 Feb 13:42    INFO  epoch 5 training [time: 54.67s, train loss: 4293.3952]
12 Feb 13:42    INFO  epoch 5 evaluating [time: 0.02s, valid_score: 0.067600]
12 Feb 13:42    INFO  valid result: 
hit@1 : 0.0138    hit@5 : 0.0795    hit@10 : 0.1474    hit@20 : 0.246    ndcg@1 : 0.0138    ndcg@5 : 0.0457    ndcg@10 : 0.0676    ndcg@20 : 0.0923    mrr@1 : 0.0138    mrr@5 : 0.0347    mrr@10 : 0.0438    mrr@20 : 0.0504
12 Feb 13:42    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:43    INFO  epoch 6 training [time: 54.82s, train loss: 4276.3975]
12 Feb 13:43    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 0.062200]
12 Feb 13:43    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.071    hit@10 : 0.1304    hit@20 : 0.2333    ndcg@1 : 0.0159    ndcg@5 : 0.0435    ndcg@10 : 0.0622    ndcg@20 : 0.0882    mrr@1 : 0.0159    mrr@5 : 0.0345    mrr@10 : 0.0419    mrr@20 : 0.0491
12 Feb 13:44    INFO  epoch 7 training [time: 54.45s, train loss: 4265.3386]
12 Feb 13:44    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.055900]
12 Feb 13:44    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0657    hit@10 : 0.123    hit@20 : 0.2365    ndcg@1 : 0.0095    ndcg@5 : 0.0376    ndcg@10 : 0.0559    ndcg@20 : 0.0846    mrr@1 : 0.0095    mrr@5 : 0.0285    mrr@10 : 0.0359    mrr@20 : 0.0437
12 Feb 13:44    INFO  epoch 8 training [time: 54.52s, train loss: 4254.8293]
12 Feb 13:44    INFO  epoch 8 evaluating [time: 0.02s, valid_score: 0.065800]
12 Feb 13:44    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0689    hit@10 : 0.141    hit@20 : 0.2439    ndcg@1 : 0.0159    ndcg@5 : 0.0431    ndcg@10 : 0.0658    ndcg@20 : 0.0915    mrr@1 : 0.0159    mrr@5 : 0.0346    mrr@10 : 0.0436    mrr@20 : 0.0505
12 Feb 13:45    INFO  epoch 9 training [time: 54.54s, train loss: 4244.7541]
12 Feb 13:45    INFO  epoch 9 evaluating [time: 0.02s, valid_score: 0.066000]
12 Feb 13:45    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0827    hit@10 : 0.1336    hit@20 : 0.245    ndcg@1 : 0.017    ndcg@5 : 0.0496    ndcg@10 : 0.066    ndcg@20 : 0.0937    mrr@1 : 0.017    mrr@5 : 0.0388    mrr@10 : 0.0455    mrr@20 : 0.0529
12 Feb 13:46    INFO  epoch 10 training [time: 54.55s, train loss: 4236.9816]
12 Feb 13:46    INFO  epoch 10 evaluating [time: 0.02s, valid_score: 0.063500]
12 Feb 13:46    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.07    hit@10 : 0.1379    hit@20 : 0.2471    ndcg@1 : 0.0127    ndcg@5 : 0.0411    ndcg@10 : 0.0635    ndcg@20 : 0.0909    mrr@1 : 0.0127    mrr@5 : 0.0317    mrr@10 : 0.0412    mrr@20 : 0.0486
12 Feb 13:47    INFO  epoch 11 training [time: 54.67s, train loss: 4227.1891]
12 Feb 13:47    INFO  epoch 11 evaluating [time: 0.02s, valid_score: 0.064600]
12 Feb 13:47    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0817    hit@10 : 0.1432    hit@20 : 0.246    ndcg@1 : 0.0095    ndcg@5 : 0.0448    ndcg@10 : 0.0646    ndcg@20 : 0.0905    mrr@1 : 0.0095    mrr@5 : 0.0328    mrr@10 : 0.0409    mrr@20 : 0.048
12 Feb 13:48    INFO  epoch 12 training [time: 54.33s, train loss: 4223.1859]
12 Feb 13:48    INFO  epoch 12 evaluating [time: 0.02s, valid_score: 0.067900]
12 Feb 13:48    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0753    hit@10 : 0.1474    hit@20 : 0.245    ndcg@1 : 0.0127    ndcg@5 : 0.0446    ndcg@10 : 0.0679    ndcg@20 : 0.0923    mrr@1 : 0.0127    mrr@5 : 0.0345    mrr@10 : 0.0441    mrr@20 : 0.0507
12 Feb 13:48    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:49    INFO  epoch 13 training [time: 54.60s, train loss: 4217.5320]
12 Feb 13:49    INFO  epoch 13 evaluating [time: 0.02s, valid_score: 0.070100]
12 Feb 13:49    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0806    hit@10 : 0.1538    hit@20 : 0.246    ndcg@1 : 0.0148    ndcg@5 : 0.0467    ndcg@10 : 0.0701    ndcg@20 : 0.0932    mrr@1 : 0.0148    mrr@5 : 0.0356    mrr@10 : 0.0451    mrr@20 : 0.0514
12 Feb 13:49    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:50    INFO  epoch 14 training [time: 54.81s, train loss: 4210.5957]
12 Feb 13:50    INFO  epoch 14 evaluating [time: 0.02s, valid_score: 0.068700]
12 Feb 13:50    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0859    hit@10 : 0.1453    hit@20 : 0.245    ndcg@1 : 0.0159    ndcg@5 : 0.0499    ndcg@10 : 0.0687    ndcg@20 : 0.0936    mrr@1 : 0.0159    mrr@5 : 0.0383    mrr@10 : 0.0457    mrr@20 : 0.0525
12 Feb 13:51    INFO  epoch 15 training [time: 54.81s, train loss: 4206.6277]
12 Feb 13:51    INFO  epoch 15 evaluating [time: 0.02s, valid_score: 0.067200]
12 Feb 13:51    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0774    hit@10 : 0.1495    hit@20 : 0.2524    ndcg@1 : 0.0106    ndcg@5 : 0.0438    ndcg@10 : 0.0672    ndcg@20 : 0.0927    mrr@1 : 0.0106    mrr@5 : 0.0329    mrr@10 : 0.0425    mrr@20 : 0.0493
12 Feb 13:52    INFO  epoch 16 training [time: 54.61s, train loss: 4200.7993]
12 Feb 13:52    INFO  epoch 16 evaluating [time: 0.02s, valid_score: 0.072500]
12 Feb 13:52    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0859    hit@10 : 0.1506    hit@20 : 0.2534    ndcg@1 : 0.017    ndcg@5 : 0.0515    ndcg@10 : 0.0725    ndcg@20 : 0.0984    mrr@1 : 0.017    mrr@5 : 0.0402    mrr@10 : 0.049    mrr@20 : 0.0561
12 Feb 13:52    INFO  Saving current: outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 13:53    INFO  epoch 17 training [time: 54.73s, train loss: 4198.5354]
12 Feb 13:53    INFO  epoch 17 evaluating [time: 0.02s, valid_score: 0.070100]
12 Feb 13:53    INFO  valid result: 
hit@1 : 0.017    hit@5 : 0.0817    hit@10 : 0.1485    hit@20 : 0.2619    ndcg@1 : 0.017    ndcg@5 : 0.0484    ndcg@10 : 0.0701    ndcg@20 : 0.0989    mrr@1 : 0.017    mrr@5 : 0.0377    mrr@10 : 0.0466    mrr@20 : 0.0546
12 Feb 13:54    INFO  epoch 18 training [time: 54.69s, train loss: 4193.6407]
12 Feb 13:54    INFO  epoch 18 evaluating [time: 0.02s, valid_score: 0.067400]
12 Feb 13:54    INFO  valid result: 
hit@1 : 0.0085    hit@5 : 0.0774    hit@10 : 0.1538    hit@20 : 0.2577    ndcg@1 : 0.0085    ndcg@5 : 0.0428    ndcg@10 : 0.0674    ndcg@20 : 0.0933    mrr@1 : 0.0085    mrr@5 : 0.0315    mrr@10 : 0.0416    mrr@20 : 0.0486
12 Feb 13:54    INFO  epoch 19 training [time: 54.23s, train loss: 4189.9171]
12 Feb 13:54    INFO  epoch 19 evaluating [time: 0.02s, valid_score: 0.067300]
12 Feb 13:54    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0785    hit@10 : 0.1516    hit@20 : 0.2534    ndcg@1 : 0.0095    ndcg@5 : 0.0441    ndcg@10 : 0.0673    ndcg@20 : 0.0929    mrr@1 : 0.0095    mrr@5 : 0.0328    mrr@10 : 0.0422    mrr@20 : 0.0491
12 Feb 13:55    INFO  epoch 20 training [time: 54.95s, train loss: 4187.1404]
12 Feb 13:55    INFO  epoch 20 evaluating [time: 0.02s, valid_score: 0.071300]
12 Feb 13:55    INFO  valid result: 
hit@1 : 0.0127    hit@5 : 0.0848    hit@10 : 0.1538    hit@20 : 0.2556    ndcg@1 : 0.0127    ndcg@5 : 0.0493    ndcg@10 : 0.0713    ndcg@20 : 0.0969    mrr@1 : 0.0127    mrr@5 : 0.0376    mrr@10 : 0.0465    mrr@20 : 0.0535
12 Feb 13:56    INFO  epoch 21 training [time: 54.90s, train loss: 4183.7061]
12 Feb 13:56    INFO  epoch 21 evaluating [time: 0.02s, valid_score: 0.068200]
12 Feb 13:56    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.087    hit@10 : 0.1495    hit@20 : 0.2609    ndcg@1 : 0.0106    ndcg@5 : 0.0481    ndcg@10 : 0.0682    ndcg@20 : 0.0964    mrr@1 : 0.0106    mrr@5 : 0.0355    mrr@10 : 0.0437    mrr@20 : 0.0515
12 Feb 13:57    INFO  epoch 22 training [time: 54.72s, train loss: 4182.6825]
12 Feb 13:57    INFO  epoch 22 evaluating [time: 0.02s, valid_score: 0.070500]
12 Feb 13:57    INFO  valid result: 
hit@1 : 0.0148    hit@5 : 0.0827    hit@10 : 0.1527    hit@20 : 0.2778    ndcg@1 : 0.0148    ndcg@5 : 0.0479    ndcg@10 : 0.0705    ndcg@20 : 0.1015    mrr@1 : 0.0148    mrr@5 : 0.0367    mrr@10 : 0.0459    mrr@20 : 0.0541
12 Feb 13:58    INFO  epoch 23 training [time: 54.57s, train loss: 4177.8142]
12 Feb 13:58    INFO  epoch 23 evaluating [time: 0.02s, valid_score: 0.072000]
12 Feb 13:58    INFO  valid result: 
hit@1 : 0.0117    hit@5 : 0.0891    hit@10 : 0.1601    hit@20 : 0.2683    ndcg@1 : 0.0117    ndcg@5 : 0.0494    ndcg@10 : 0.072    ndcg@20 : 0.0991    mrr@1 : 0.0117    mrr@5 : 0.0365    mrr@10 : 0.0456    mrr@20 : 0.0529
12 Feb 13:59    INFO  epoch 24 training [time: 54.26s, train loss: 4174.1396]
12 Feb 13:59    INFO  epoch 24 evaluating [time: 0.02s, valid_score: 0.067700]
12 Feb 13:59    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0827    hit@10 : 0.1548    hit@20 : 0.2545    ndcg@1 : 0.0106    ndcg@5 : 0.0448    ndcg@10 : 0.0677    ndcg@20 : 0.0926    mrr@1 : 0.0106    mrr@5 : 0.0325    mrr@10 : 0.0418    mrr@20 : 0.0485
12 Feb 14:00    INFO  epoch 25 training [time: 54.51s, train loss: 4172.6414]
12 Feb 14:00    INFO  epoch 25 evaluating [time: 0.02s, valid_score: 0.070500]
12 Feb 14:00    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.0806    hit@10 : 0.1601    hit@20 : 0.2503    ndcg@1 : 0.0095    ndcg@5 : 0.0453    ndcg@10 : 0.0705    ndcg@20 : 0.0933    mrr@1 : 0.0095    mrr@5 : 0.0337    mrr@10 : 0.0439    mrr@20 : 0.0502
12 Feb 14:01    INFO  epoch 26 training [time: 54.36s, train loss: 4169.6346]
12 Feb 14:01    INFO  epoch 26 evaluating [time: 0.02s, valid_score: 0.071600]
12 Feb 14:01    INFO  valid result: 
hit@1 : 0.0159    hit@5 : 0.0944    hit@10 : 0.1506    hit@20 : 0.2598    ndcg@1 : 0.0159    ndcg@5 : 0.0537    ndcg@10 : 0.0716    ndcg@20 : 0.099    mrr@1 : 0.0159    mrr@5 : 0.0405    mrr@10 : 0.0478    mrr@20 : 0.0552
12 Feb 14:02    INFO  epoch 27 training [time: 54.70s, train loss: 4166.5562]
12 Feb 14:02    INFO  epoch 27 evaluating [time: 0.02s, valid_score: 0.067000]
12 Feb 14:02    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0817    hit@10 : 0.1527    hit@20 : 0.2672    ndcg@1 : 0.0106    ndcg@5 : 0.0441    ndcg@10 : 0.067    ndcg@20 : 0.0956    mrr@1 : 0.0106    mrr@5 : 0.032    mrr@10 : 0.0414    mrr@20 : 0.0491
12 Feb 14:02    INFO  Finished training, best eval result in epoch 16
12 Feb 14:02    INFO  Loading model structure and parameters from outputs/pswrecv5_ml100k/pswrecv5-Feb-12-2026_13-36-41.pth
12 Feb 14:02    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      2.10 %      |
+-------------+------------------+
| GPU         |  0.55 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.42 G/2015.66 G |
+-------------+------------------+
12 Feb 14:02    INFO  best valid : OrderedDict([('hit@1', 0.017), ('hit@5', 0.0859), ('hit@10', 0.1506), ('hit@20', 0.2534), ('ndcg@1', 0.017), ('ndcg@5', 0.0515), ('ndcg@10', 0.0725), ('ndcg@20', 0.0984), ('mrr@1', 0.017), ('mrr@5', 0.0402), ('mrr@10', 0.049), ('mrr@20', 0.0561)])
12 Feb 14:02    INFO  test result: OrderedDict([('hit@1', 0.018), ('hit@5', 0.0732), ('hit@10', 0.1304), ('hit@20', 0.2397), ('ndcg@1', 0.018), ('ndcg@5', 0.0453), ('ndcg@10', 0.0635), ('ndcg@20', 0.0908), ('mrr@1', 0.018), ('mrr@5', 0.0362), ('mrr@10', 0.0435), ('mrr@20', 0.0508)])
