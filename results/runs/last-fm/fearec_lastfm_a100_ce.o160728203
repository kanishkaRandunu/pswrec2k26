=== hostname ===
gadi-dgx-a100-0001.gadi.nci.org.au
=== PBS_JOBID ===
160728203.gadi-pbs
command line args [-m FEARec -d lastfm --config_files configs/lastfm/lastfm_FEARec.yaml] will not be used in RecBole
12 Feb 13:02    INFO  ['RecBole/run_recbole.py', '-m', 'FEARec', '-d', 'lastfm', '--config_files', 'configs/lastfm/lastfm_FEARec.yaml']
12 Feb 13:02    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /scratch/up63/kd6504/recbole_datasets/lastfm
checkpoint_dir = outputs/fearec_lastfm
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [1, 5, 10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = artist_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'artist_id', 'timestamp']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
lmd = 0.1
lmd_sem = 0.1
global_ratio = 1
dual_domain = False
std = False
spatial_ratio = 0
fredom = False
fredom_type = None
topk_factor = 1
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
12 Feb 13:02    INFO  lastfm
The number of users: 1091
Average actions of users: 48.21192660550459
The number of items: 3647
Average actions of items: 14.413329676357652
The number of inters: 52551
The sparsity of the dataset: 98.67925045182346%
Remain Fields: ['user_id', 'artist_id', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
12 Feb 13:02    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
12 Feb 13:02    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
1>0.5:True
modes_q=26, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_k=26, index_k=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_v=26, index_v=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
1>0.5:True
modes_q=26, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_k=26, index_k=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_v=26, index_v=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
12 Feb 13:02    INFO  FEARec(
  (item_embedding): Embedding(3647, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (item_encoder): FEAEncoder(
    (layer): ModuleList(
      (0-1): 2 x FEABlock(
        (hybrid_attention): HybridAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (query_layer): Linear(in_features=64, out_features=64, bias=True)
          (key_layer): Linear(in_features=64, out_features=64, bias=True)
          (value_layer): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (layer_ramp): FEABlock(
      (hybrid_attention): HybridAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (query_layer): Linear(in_features=64, out_features=64, bias=True)
        (key_layer): Linear(in_features=64, out_features=64, bias=True)
        (value_layer): Linear(in_features=64, out_features=64, bias=True)
        (attn_dropout): Dropout(p=0.5, inplace=False)
        (dense): Linear(in_features=64, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (out_dropout): Dropout(p=0.5, inplace=False)
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
  (aug_nce_fct): CrossEntropyLoss()
  (sem_aug_nce_fct): CrossEntropyLoss()
)
Trainable parameters: 336704
12 Feb 13:02    INFO  FLOPs: 12364864.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
12 Feb 13:02    INFO  epoch 0 training [time: 25.44s, train loss: 3006.4206]
12 Feb 13:02    INFO  epoch 0 evaluating [time: 0.06s, valid_score: 0.018200]
12 Feb 13:02    INFO  valid result: 
hit@1 : 0.0083    hit@5 : 0.0183    hit@10 : 0.0339    hit@20 : 0.0477    ndcg@1 : 0.0083    ndcg@5 : 0.0133    ndcg@10 : 0.0182    ndcg@20 : 0.0216    mrr@1 : 0.0083    mrr@5 : 0.0117    mrr@10 : 0.0136    mrr@20 : 0.0145
12 Feb 13:02    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:03    INFO  epoch 1 training [time: 25.87s, train loss: 2775.1061]
12 Feb 13:03    INFO  epoch 1 evaluating [time: 0.10s, valid_score: 0.026800]
12 Feb 13:03    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.0358    hit@10 : 0.0532    hit@20 : 0.0817    ndcg@1 : 0.0064    ndcg@5 : 0.0213    ndcg@10 : 0.0268    ndcg@20 : 0.034    mrr@1 : 0.0064    mrr@5 : 0.0165    mrr@10 : 0.0188    mrr@20 : 0.0207
12 Feb 13:03    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:03    INFO  epoch 2 training [time: 25.79s, train loss: 2594.4832]
12 Feb 13:03    INFO  epoch 2 evaluating [time: 0.04s, valid_score: 0.029100]
12 Feb 13:03    INFO  valid result: 
hit@1 : 0.0083    hit@5 : 0.0385    hit@10 : 0.0569    hit@20 : 0.0881    ndcg@1 : 0.0083    ndcg@5 : 0.0231    ndcg@10 : 0.0291    ndcg@20 : 0.037    mrr@1 : 0.0083    mrr@5 : 0.0181    mrr@10 : 0.0206    mrr@20 : 0.0227
12 Feb 13:03    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:04    INFO  epoch 3 training [time: 26.51s, train loss: 2460.8029]
12 Feb 13:04    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.028400]
12 Feb 13:04    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.0404    hit@10 : 0.0606    hit@20 : 0.1009    ndcg@1 : 0.0037    ndcg@5 : 0.0221    ndcg@10 : 0.0284    ndcg@20 : 0.0386    mrr@1 : 0.0037    mrr@5 : 0.0161    mrr@10 : 0.0186    mrr@20 : 0.0214
12 Feb 13:04    INFO  epoch 4 training [time: 25.94s, train loss: 2375.3432]
12 Feb 13:04    INFO  epoch 4 evaluating [time: 0.04s, valid_score: 0.031700]
12 Feb 13:04    INFO  valid result: 
hit@1 : 0.0055    hit@5 : 0.0413    hit@10 : 0.0651    hit@20 : 0.0991    ndcg@1 : 0.0055    ndcg@5 : 0.0239    ndcg@10 : 0.0317    ndcg@20 : 0.0403    mrr@1 : 0.0055    mrr@5 : 0.0182    mrr@10 : 0.0215    mrr@20 : 0.0238
12 Feb 13:04    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:04    INFO  epoch 5 training [time: 25.46s, train loss: 2316.5683]
12 Feb 13:04    INFO  epoch 5 evaluating [time: 0.03s, valid_score: 0.033600]
12 Feb 13:04    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.0468    hit@10 : 0.0679    hit@20 : 0.0972    ndcg@1 : 0.0064    ndcg@5 : 0.0269    ndcg@10 : 0.0336    ndcg@20 : 0.0408    mrr@1 : 0.0064    mrr@5 : 0.0204    mrr@10 : 0.0231    mrr@20 : 0.025
12 Feb 13:04    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:05    INFO  epoch 6 training [time: 25.40s, train loss: 2276.1543]
12 Feb 13:05    INFO  epoch 6 evaluating [time: 0.03s, valid_score: 0.035600]
12 Feb 13:05    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.0486    hit@10 : 0.0752    hit@20 : 0.1018    ndcg@1 : 0.0064    ndcg@5 : 0.0272    ndcg@10 : 0.0356    ndcg@20 : 0.0423    mrr@1 : 0.0064    mrr@5 : 0.0203    mrr@10 : 0.0236    mrr@20 : 0.0254
12 Feb 13:05    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:05    INFO  epoch 7 training [time: 25.44s, train loss: 2241.1820]
12 Feb 13:05    INFO  epoch 7 evaluating [time: 0.03s, valid_score: 0.035100]
12 Feb 13:05    INFO  valid result: 
hit@1 : 0.0055    hit@5 : 0.0431    hit@10 : 0.0761    hit@20 : 0.1037    ndcg@1 : 0.0055    ndcg@5 : 0.0245    ndcg@10 : 0.0351    ndcg@20 : 0.0421    mrr@1 : 0.0055    mrr@5 : 0.0184    mrr@10 : 0.0228    mrr@20 : 0.0246
12 Feb 13:06    INFO  epoch 8 training [time: 25.44s, train loss: 2215.6384]
12 Feb 13:06    INFO  epoch 8 evaluating [time: 0.03s, valid_score: 0.031200]
12 Feb 13:06    INFO  valid result: 
hit@1 : 0.0009    hit@5 : 0.0477    hit@10 : 0.067    hit@20 : 0.1009    ndcg@1 : 0.0009    ndcg@5 : 0.0252    ndcg@10 : 0.0312    ndcg@20 : 0.0398    mrr@1 : 0.0009    mrr@5 : 0.0178    mrr@10 : 0.0202    mrr@20 : 0.0225
12 Feb 13:06    INFO  epoch 9 training [time: 25.44s, train loss: 2195.6108]
12 Feb 13:06    INFO  epoch 9 evaluating [time: 0.03s, valid_score: 0.032600]
12 Feb 13:06    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.045    hit@10 : 0.0679    hit@20 : 0.1064    ndcg@1 : 0.0046    ndcg@5 : 0.0252    ndcg@10 : 0.0326    ndcg@20 : 0.0423    mrr@1 : 0.0046    mrr@5 : 0.0187    mrr@10 : 0.0217    mrr@20 : 0.0244
12 Feb 13:07    INFO  epoch 10 training [time: 25.39s, train loss: 2177.9757]
12 Feb 13:07    INFO  epoch 10 evaluating [time: 0.03s, valid_score: 0.034700]
12 Feb 13:07    INFO  valid result: 
hit@1 : 0.0055    hit@5 : 0.0404    hit@10 : 0.0761    hit@20 : 0.1101    ndcg@1 : 0.0055    ndcg@5 : 0.0232    ndcg@10 : 0.0347    ndcg@20 : 0.0432    mrr@1 : 0.0055    mrr@5 : 0.0176    mrr@10 : 0.0223    mrr@20 : 0.0246
12 Feb 13:07    INFO  epoch 11 training [time: 25.48s, train loss: 2162.3941]
12 Feb 13:07    INFO  epoch 11 evaluating [time: 0.03s, valid_score: 0.032000]
12 Feb 13:07    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.0394    hit@10 : 0.0688    hit@20 : 0.111    ndcg@1 : 0.0046    ndcg@5 : 0.0227    ndcg@10 : 0.032    ndcg@20 : 0.0426    mrr@1 : 0.0046    mrr@5 : 0.0172    mrr@10 : 0.0209    mrr@20 : 0.0238
12 Feb 13:07    INFO  epoch 12 training [time: 25.46s, train loss: 2152.4958]
12 Feb 13:07    INFO  epoch 12 evaluating [time: 0.03s, valid_score: 0.034900]
12 Feb 13:07    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.045    hit@10 : 0.0761    hit@20 : 0.1101    ndcg@1 : 0.0046    ndcg@5 : 0.0248    ndcg@10 : 0.0349    ndcg@20 : 0.0435    mrr@1 : 0.0046    mrr@5 : 0.0182    mrr@10 : 0.0224    mrr@20 : 0.0248
12 Feb 13:08    INFO  epoch 13 training [time: 25.53s, train loss: 2141.8761]
12 Feb 13:08    INFO  epoch 13 evaluating [time: 0.03s, valid_score: 0.031300]
12 Feb 13:08    INFO  valid result: 
hit@1 : 0.0028    hit@5 : 0.0422    hit@10 : 0.0716    hit@20 : 0.1119    ndcg@1 : 0.0028    ndcg@5 : 0.0219    ndcg@10 : 0.0313    ndcg@20 : 0.0415    mrr@1 : 0.0028    mrr@5 : 0.0154    mrr@10 : 0.0191    mrr@20 : 0.022
12 Feb 13:08    INFO  epoch 14 training [time: 25.52s, train loss: 2130.4300]
12 Feb 13:08    INFO  epoch 14 evaluating [time: 0.03s, valid_score: 0.034200]
12 Feb 13:08    INFO  valid result: 
hit@1 : 0.0028    hit@5 : 0.0486    hit@10 : 0.0743    hit@20 : 0.1055    ndcg@1 : 0.0028    ndcg@5 : 0.0258    ndcg@10 : 0.0342    ndcg@20 : 0.0421    mrr@1 : 0.0028    mrr@5 : 0.0183    mrr@10 : 0.0219    mrr@20 : 0.024
12 Feb 13:09    INFO  epoch 15 training [time: 25.57s, train loss: 2125.8479]
12 Feb 13:09    INFO  epoch 15 evaluating [time: 0.03s, valid_score: 0.035900]
12 Feb 13:09    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.0468    hit@10 : 0.0734    hit@20 : 0.1128    ndcg@1 : 0.0064    ndcg@5 : 0.0272    ndcg@10 : 0.0359    ndcg@20 : 0.0458    mrr@1 : 0.0064    mrr@5 : 0.0208    mrr@10 : 0.0245    mrr@20 : 0.0271
12 Feb 13:09    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:09    INFO  epoch 16 training [time: 25.45s, train loss: 2116.0742]
12 Feb 13:09    INFO  epoch 16 evaluating [time: 0.03s, valid_score: 0.033400]
12 Feb 13:09    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.044    hit@10 : 0.0688    hit@20 : 0.1138    ndcg@1 : 0.0064    ndcg@5 : 0.0252    ndcg@10 : 0.0334    ndcg@20 : 0.0447    mrr@1 : 0.0064    mrr@5 : 0.0191    mrr@10 : 0.0226    mrr@20 : 0.0256
12 Feb 13:10    INFO  epoch 17 training [time: 25.41s, train loss: 2108.1684]
12 Feb 13:10    INFO  epoch 17 evaluating [time: 0.03s, valid_score: 0.033700]
12 Feb 13:10    INFO  valid result: 
hit@1 : 0.0055    hit@5 : 0.0459    hit@10 : 0.0697    hit@20 : 0.111    ndcg@1 : 0.0055    ndcg@5 : 0.0262    ndcg@10 : 0.0337    ndcg@20 : 0.044    mrr@1 : 0.0055    mrr@5 : 0.0198    mrr@10 : 0.0227    mrr@20 : 0.0254
12 Feb 13:10    INFO  epoch 18 training [time: 25.43s, train loss: 2103.1468]
12 Feb 13:10    INFO  epoch 18 evaluating [time: 0.03s, valid_score: 0.033300]
12 Feb 13:10    INFO  valid result: 
hit@1 : 0.0    hit@5 : 0.0468    hit@10 : 0.0761    hit@20 : 0.1073    ndcg@1 : 0.0    ndcg@5 : 0.0238    ndcg@10 : 0.0333    ndcg@20 : 0.041    mrr@1 : 0.0    mrr@5 : 0.0162    mrr@10 : 0.0201    mrr@20 : 0.0221
12 Feb 13:10    INFO  epoch 19 training [time: 25.42s, train loss: 2098.8385]
12 Feb 13:10    INFO  epoch 19 evaluating [time: 0.03s, valid_score: 0.034900]
12 Feb 13:10    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.0495    hit@10 : 0.0734    hit@20 : 0.1119    ndcg@1 : 0.0046    ndcg@5 : 0.0272    ndcg@10 : 0.0349    ndcg@20 : 0.0445    mrr@1 : 0.0046    mrr@5 : 0.0199    mrr@10 : 0.023    mrr@20 : 0.0256
12 Feb 13:11    INFO  epoch 20 training [time: 25.56s, train loss: 2096.4188]
12 Feb 13:11    INFO  epoch 20 evaluating [time: 0.03s, valid_score: 0.035700]
12 Feb 13:11    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.045    hit@10 : 0.0761    hit@20 : 0.1147    ndcg@1 : 0.0037    ndcg@5 : 0.0257    ndcg@10 : 0.0357    ndcg@20 : 0.0454    mrr@1 : 0.0037    mrr@5 : 0.0193    mrr@10 : 0.0234    mrr@20 : 0.026
12 Feb 13:11    INFO  epoch 21 training [time: 25.49s, train loss: 2089.4440]
12 Feb 13:11    INFO  epoch 21 evaluating [time: 0.03s, valid_score: 0.033000]
12 Feb 13:11    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.0459    hit@10 : 0.0716    hit@20 : 0.1165    ndcg@1 : 0.0037    ndcg@5 : 0.0246    ndcg@10 : 0.033    ndcg@20 : 0.0442    mrr@1 : 0.0037    mrr@5 : 0.0177    mrr@10 : 0.0212    mrr@20 : 0.0242
12 Feb 13:12    INFO  epoch 22 training [time: 25.48s, train loss: 2080.1567]
12 Feb 13:12    INFO  epoch 22 evaluating [time: 0.03s, valid_score: 0.033900]
12 Feb 13:12    INFO  valid result: 
hit@1 : 0.0028    hit@5 : 0.0431    hit@10 : 0.0725    hit@20 : 0.1055    ndcg@1 : 0.0028    ndcg@5 : 0.0241    ndcg@10 : 0.0339    ndcg@20 : 0.0422    mrr@1 : 0.0028    mrr@5 : 0.0178    mrr@10 : 0.022    mrr@20 : 0.0242
12 Feb 13:12    INFO  epoch 23 training [time: 25.44s, train loss: 2073.0925]
12 Feb 13:12    INFO  epoch 23 evaluating [time: 0.03s, valid_score: 0.031600]
12 Feb 13:12    INFO  valid result: 
hit@1 : 0.0055    hit@5 : 0.0413    hit@10 : 0.0642    hit@20 : 0.1092    ndcg@1 : 0.0055    ndcg@5 : 0.0244    ndcg@10 : 0.0316    ndcg@20 : 0.0429    mrr@1 : 0.0055    mrr@5 : 0.0188    mrr@10 : 0.0217    mrr@20 : 0.0247
12 Feb 13:13    INFO  epoch 24 training [time: 25.47s, train loss: 2072.7268]
12 Feb 13:13    INFO  epoch 24 evaluating [time: 0.03s, valid_score: 0.036800]
12 Feb 13:13    INFO  valid result: 
hit@1 : 0.0092    hit@5 : 0.045    hit@10 : 0.0743    hit@20 : 0.1147    ndcg@1 : 0.0092    ndcg@5 : 0.0272    ndcg@10 : 0.0368    ndcg@20 : 0.047    mrr@1 : 0.0092    mrr@5 : 0.0214    mrr@10 : 0.0254    mrr@20 : 0.0282
12 Feb 13:13    INFO  Saving current: outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:13    INFO  epoch 25 training [time: 25.47s, train loss: 2068.5365]
12 Feb 13:13    INFO  epoch 25 evaluating [time: 0.03s, valid_score: 0.035100]
12 Feb 13:13    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.0477    hit@10 : 0.0761    hit@20 : 0.1147    ndcg@1 : 0.0046    ndcg@5 : 0.0261    ndcg@10 : 0.0351    ndcg@20 : 0.0447    mrr@1 : 0.0046    mrr@5 : 0.019    mrr@10 : 0.0227    mrr@20 : 0.0252
12 Feb 13:13    INFO  epoch 26 training [time: 25.41s, train loss: 2060.7602]
12 Feb 13:13    INFO  epoch 26 evaluating [time: 0.03s, valid_score: 0.033500]
12 Feb 13:13    INFO  valid result: 
hit@1 : 0.0064    hit@5 : 0.045    hit@10 : 0.0661    hit@20 : 0.1202    ndcg@1 : 0.0064    ndcg@5 : 0.0266    ndcg@10 : 0.0335    ndcg@20 : 0.0471    mrr@1 : 0.0064    mrr@5 : 0.0206    mrr@10 : 0.0234    mrr@20 : 0.0271
12 Feb 13:14    INFO  epoch 27 training [time: 25.49s, train loss: 2063.1833]
12 Feb 13:14    INFO  epoch 27 evaluating [time: 0.03s, valid_score: 0.033100]
12 Feb 13:14    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.0459    hit@10 : 0.0697    hit@20 : 0.1101    ndcg@1 : 0.0037    ndcg@5 : 0.0253    ndcg@10 : 0.0331    ndcg@20 : 0.0435    mrr@1 : 0.0037    mrr@5 : 0.0185    mrr@10 : 0.0218    mrr@20 : 0.0248
12 Feb 13:14    INFO  epoch 28 training [time: 25.44s, train loss: 2058.5865]
12 Feb 13:14    INFO  epoch 28 evaluating [time: 0.03s, valid_score: 0.035000]
12 Feb 13:14    INFO  valid result: 
hit@1 : 0.0018    hit@5 : 0.0477    hit@10 : 0.0807    hit@20 : 0.1239    ndcg@1 : 0.0018    ndcg@5 : 0.0244    ndcg@10 : 0.035    ndcg@20 : 0.0457    mrr@1 : 0.0018    mrr@5 : 0.0168    mrr@10 : 0.0212    mrr@20 : 0.024
12 Feb 13:15    INFO  epoch 29 training [time: 25.43s, train loss: 2049.7205]
12 Feb 13:15    INFO  epoch 29 evaluating [time: 0.03s, valid_score: 0.034500]
12 Feb 13:15    INFO  valid result: 
hit@1 : 0.0028    hit@5 : 0.045    hit@10 : 0.0752    hit@20 : 0.1138    ndcg@1 : 0.0028    ndcg@5 : 0.0247    ndcg@10 : 0.0345    ndcg@20 : 0.0441    mrr@1 : 0.0028    mrr@5 : 0.018    mrr@10 : 0.0221    mrr@20 : 0.0246
12 Feb 13:15    INFO  epoch 30 training [time: 25.43s, train loss: 2052.2809]
12 Feb 13:15    INFO  epoch 30 evaluating [time: 0.03s, valid_score: 0.034000]
12 Feb 13:15    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.0486    hit@10 : 0.0725    hit@20 : 0.1147    ndcg@1 : 0.0037    ndcg@5 : 0.0263    ndcg@10 : 0.034    ndcg@20 : 0.0444    mrr@1 : 0.0037    mrr@5 : 0.019    mrr@10 : 0.0221    mrr@20 : 0.0249
12 Feb 13:15    INFO  epoch 31 training [time: 25.50s, train loss: 2044.4231]
12 Feb 13:15    INFO  epoch 31 evaluating [time: 0.03s, valid_score: 0.036500]
12 Feb 13:15    INFO  valid result: 
hit@1 : 0.0083    hit@5 : 0.045    hit@10 : 0.0761    hit@20 : 0.1248    ndcg@1 : 0.0083    ndcg@5 : 0.0265    ndcg@10 : 0.0365    ndcg@20 : 0.0487    mrr@1 : 0.0083    mrr@5 : 0.0205    mrr@10 : 0.0246    mrr@20 : 0.0279
12 Feb 13:16    INFO  epoch 32 training [time: 25.46s, train loss: 2045.9969]
12 Feb 13:16    INFO  epoch 32 evaluating [time: 0.03s, valid_score: 0.034100]
12 Feb 13:16    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.0495    hit@10 : 0.0725    hit@20 : 0.1064    ndcg@1 : 0.0037    ndcg@5 : 0.0268    ndcg@10 : 0.0341    ndcg@20 : 0.0426    mrr@1 : 0.0037    mrr@5 : 0.0194    mrr@10 : 0.0224    mrr@20 : 0.0246
12 Feb 13:16    INFO  epoch 33 training [time: 25.47s, train loss: 2042.1059]
12 Feb 13:16    INFO  epoch 33 evaluating [time: 0.03s, valid_score: 0.035800]
12 Feb 13:16    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.045    hit@10 : 0.0798    hit@20 : 0.1064    ndcg@1 : 0.0046    ndcg@5 : 0.0247    ndcg@10 : 0.0358    ndcg@20 : 0.0424    mrr@1 : 0.0046    mrr@5 : 0.0181    mrr@10 : 0.0225    mrr@20 : 0.0243
12 Feb 13:17    INFO  epoch 34 training [time: 25.41s, train loss: 2032.2333]
12 Feb 13:17    INFO  epoch 34 evaluating [time: 0.03s, valid_score: 0.035200]
12 Feb 13:17    INFO  valid result: 
hit@1 : 0.0037    hit@5 : 0.045    hit@10 : 0.0761    hit@20 : 0.1202    ndcg@1 : 0.0037    ndcg@5 : 0.0251    ndcg@10 : 0.0352    ndcg@20 : 0.0462    mrr@1 : 0.0037    mrr@5 : 0.0185    mrr@10 : 0.0227    mrr@20 : 0.0257
12 Feb 13:17    INFO  epoch 35 training [time: 25.46s, train loss: 2034.8811]
12 Feb 13:17    INFO  epoch 35 evaluating [time: 0.03s, valid_score: 0.032700]
12 Feb 13:17    INFO  valid result: 
hit@1 : 0.0028    hit@5 : 0.0413    hit@10 : 0.0752    hit@20 : 0.111    ndcg@1 : 0.0028    ndcg@5 : 0.0218    ndcg@10 : 0.0327    ndcg@20 : 0.0417    mrr@1 : 0.0028    mrr@5 : 0.0154    mrr@10 : 0.02    mrr@20 : 0.0224
12 Feb 13:17    INFO  Finished training, best eval result in epoch 24
12 Feb 13:17    INFO  Loading model structure and parameters from outputs/fearec_lastfm/FEARec-Feb-12-2026_13-02-19.pth
12 Feb 13:17    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      3.00 %      |
+-------------+------------------+
| GPU         |  0.71 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.26 G/2015.66 G |
+-------------+------------------+
12 Feb 13:17    INFO  best valid : OrderedDict([('hit@1', 0.0092), ('hit@5', 0.045), ('hit@10', 0.0743), ('hit@20', 0.1147), ('ndcg@1', 0.0092), ('ndcg@5', 0.0272), ('ndcg@10', 0.0368), ('ndcg@20', 0.047), ('mrr@1', 0.0092), ('mrr@5', 0.0214), ('mrr@10', 0.0254), ('mrr@20', 0.0282)])
12 Feb 13:17    INFO  test result: OrderedDict([('hit@1', 0.0055), ('hit@5', 0.0312), ('hit@10', 0.0495), ('hit@20', 0.0679), ('ndcg@1', 0.0055), ('ndcg@5', 0.0191), ('ndcg@10', 0.0251), ('ndcg@20', 0.0297), ('mrr@1', 0.0055), ('mrr@5', 0.0151), ('mrr@10', 0.0176), ('mrr@20', 0.0189)])
Job completed.

======================================================================================
                  Resource Usage on 2026-02-12 13:17:47:
   Job Id:             160728203.gadi-pbs
   Project:            up63
   Exit Status:        0
   Service Units:      18.70
   NCPUs Requested:    16                  CPU Time Used: 00:15:28        
   Memory Requested:   16.0GB                Memory Used: 1.28GB          
   NGPUs Requested:    1                 GPU Utilisation: 12%             
                                         GPU Memory Used: 1.21GB          
   Walltime Requested: 04:00:00            Walltime Used: 00:15:35        
   JobFS Requested:    100.0MB                JobFS Used: 5.03KB          
======================================================================================
