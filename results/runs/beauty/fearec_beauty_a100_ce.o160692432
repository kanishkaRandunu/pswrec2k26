=== hostname ===
gadi-dgx-a100-0001.gadi.nci.org.au
=== PBS_JOBID ===
160692432.gadi-pbs
command line args [-m FEARec -d amazon-beauty --config_files configs/beauty/beauty_FEARec.yaml] will not be used in RecBole
11 Feb 23:09    INFO  ['RecBole/run_recbole.py', '-m', 'FEARec', '-d', 'amazon-beauty', '--config_files', 'configs/beauty/beauty_FEARec.yaml']
11 Feb 23:09    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /scratch/up63/kd6504/recbole_datasets/amazon-beauty
checkpoint_dir = outputs/fearec_beauty
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR']
topk = [1, 5, 10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = {'inter': ['rating']}
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
lmd = 0.1
lmd_sem = 0.1
global_ratio = 1
dual_domain = False
std = False
spatial_ratio = 0
fredom = False
fredom_type = None
topk_factor = 1
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
11 Feb 23:10    INFO  amazon-beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
11 Feb 23:10    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
11 Feb 23:10    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
1>0.5:True
modes_q=26, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_k=26, index_k=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_v=26, index_v=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
1>0.5:True
modes_q=26, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_k=26, index_k=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
modes_v=26, index_v=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
11 Feb 23:10    INFO  FEARec(
  (item_embedding): Embedding(12102, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (item_encoder): FEAEncoder(
    (layer): ModuleList(
      (0-1): 2 x FEABlock(
        (hybrid_attention): HybridAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (query_layer): Linear(in_features=64, out_features=64, bias=True)
          (key_layer): Linear(in_features=64, out_features=64, bias=True)
          (value_layer): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (layer_ramp): FEABlock(
      (hybrid_attention): HybridAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (query_layer): Linear(in_features=64, out_features=64, bias=True)
        (key_layer): Linear(in_features=64, out_features=64, bias=True)
        (value_layer): Linear(in_features=64, out_features=64, bias=True)
        (attn_dropout): Dropout(p=0.5, inplace=False)
        (dense): Linear(in_features=64, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (out_dropout): Dropout(p=0.5, inplace=False)
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
  (aug_nce_fct): CrossEntropyLoss()
  (sem_aug_nce_fct): CrossEntropyLoss()
)
Trainable parameters: 877824
11 Feb 23:10    INFO  FLOPs: 12364864.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
11 Feb 23:11    INFO  epoch 0 training [time: 69.42s, train loss: 8852.7323]
11 Feb 23:11    INFO  epoch 0 evaluating [time: 1.06s, valid_score: 0.018300]
11 Feb 23:11    INFO  valid result: 
hit@1 : 0.0046    hit@5 : 0.0216    hit@10 : 0.0379    hit@20 : 0.0611    ndcg@1 : 0.0046    ndcg@5 : 0.0131    ndcg@10 : 0.0183    ndcg@20 : 0.0241    mrr@1 : 0.0046    mrr@5 : 0.0103    mrr@10 : 0.0124    mrr@20 : 0.014
11 Feb 23:11    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:12    INFO  epoch 1 training [time: 68.82s, train loss: 8188.0890]
11 Feb 23:12    INFO  epoch 1 evaluating [time: 1.02s, valid_score: 0.029400]
11 Feb 23:12    INFO  valid result: 
hit@1 : 0.0089    hit@5 : 0.0357    hit@10 : 0.0571    hit@20 : 0.0846    ndcg@1 : 0.0089    ndcg@5 : 0.0225    ndcg@10 : 0.0294    ndcg@20 : 0.0363    mrr@1 : 0.0089    mrr@5 : 0.0181    mrr@10 : 0.021    mrr@20 : 0.0228
11 Feb 23:12    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:13    INFO  epoch 2 training [time: 69.19s, train loss: 7866.4107]
11 Feb 23:13    INFO  epoch 2 evaluating [time: 1.02s, valid_score: 0.036100]
11 Feb 23:13    INFO  valid result: 
hit@1 : 0.0112    hit@5 : 0.0463    hit@10 : 0.0698    hit@20 : 0.1058    ndcg@1 : 0.0112    ndcg@5 : 0.0285    ndcg@10 : 0.0361    ndcg@20 : 0.0451    mrr@1 : 0.0112    mrr@5 : 0.0228    mrr@10 : 0.0259    mrr@20 : 0.0283
11 Feb 23:13    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:14    INFO  epoch 3 training [time: 68.91s, train loss: 7613.3707]
11 Feb 23:14    INFO  epoch 3 evaluating [time: 1.02s, valid_score: 0.041600]
11 Feb 23:14    INFO  valid result: 
hit@1 : 0.0104    hit@5 : 0.0533    hit@10 : 0.0839    hit@20 : 0.122    ndcg@1 : 0.0104    ndcg@5 : 0.0318    ndcg@10 : 0.0416    ndcg@20 : 0.0512    mrr@1 : 0.0104    mrr@5 : 0.0248    mrr@10 : 0.0288    mrr@20 : 0.0314
11 Feb 23:14    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:16    INFO  epoch 4 training [time: 68.94s, train loss: 7412.2195]
11 Feb 23:16    INFO  epoch 4 evaluating [time: 1.02s, valid_score: 0.045300]
11 Feb 23:16    INFO  valid result: 
hit@1 : 0.0114    hit@5 : 0.0592    hit@10 : 0.0888    hit@20 : 0.1286    ndcg@1 : 0.0114    ndcg@5 : 0.0358    ndcg@10 : 0.0453    ndcg@20 : 0.0553    mrr@1 : 0.0114    mrr@5 : 0.028    mrr@10 : 0.0319    mrr@20 : 0.0346
11 Feb 23:16    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:17    INFO  epoch 5 training [time: 69.02s, train loss: 7248.5834]
11 Feb 23:17    INFO  epoch 5 evaluating [time: 1.02s, valid_score: 0.046800]
11 Feb 23:17    INFO  valid result: 
hit@1 : 0.0103    hit@5 : 0.0628    hit@10 : 0.0935    hit@20 : 0.1328    ndcg@1 : 0.0103    ndcg@5 : 0.037    ndcg@10 : 0.0468    ndcg@20 : 0.0567    mrr@1 : 0.0103    mrr@5 : 0.0285    mrr@10 : 0.0326    mrr@20 : 0.0352
11 Feb 23:17    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:18    INFO  epoch 6 training [time: 68.99s, train loss: 7122.2468]
11 Feb 23:18    INFO  epoch 6 evaluating [time: 1.01s, valid_score: 0.047900]
11 Feb 23:18    INFO  valid result: 
hit@1 : 0.0107    hit@5 : 0.0635    hit@10 : 0.0953    hit@20 : 0.1367    ndcg@1 : 0.0107    ndcg@5 : 0.0377    ndcg@10 : 0.0479    ndcg@20 : 0.0583    mrr@1 : 0.0107    mrr@5 : 0.0292    mrr@10 : 0.0334    mrr@20 : 0.0362
11 Feb 23:18    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:19    INFO  epoch 7 training [time: 68.88s, train loss: 7022.2057]
11 Feb 23:19    INFO  epoch 7 evaluating [time: 1.02s, valid_score: 0.048300]
11 Feb 23:19    INFO  valid result: 
hit@1 : 0.0102    hit@5 : 0.0633    hit@10 : 0.0967    hit@20 : 0.1403    ndcg@1 : 0.0102    ndcg@5 : 0.0376    ndcg@10 : 0.0483    ndcg@20 : 0.0593    mrr@1 : 0.0102    mrr@5 : 0.0291    mrr@10 : 0.0335    mrr@20 : 0.0365
11 Feb 23:19    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:20    INFO  epoch 8 training [time: 69.05s, train loss: 6939.4987]
11 Feb 23:20    INFO  epoch 8 evaluating [time: 1.02s, valid_score: 0.049600]
11 Feb 23:20    INFO  valid result: 
hit@1 : 0.0108    hit@5 : 0.0656    hit@10 : 0.0989    hit@20 : 0.1389    ndcg@1 : 0.0108    ndcg@5 : 0.0389    ndcg@10 : 0.0496    ndcg@20 : 0.0597    mrr@1 : 0.0108    mrr@5 : 0.0302    mrr@10 : 0.0345    mrr@20 : 0.0373
11 Feb 23:20    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:21    INFO  epoch 9 training [time: 68.84s, train loss: 6874.6998]
11 Feb 23:21    INFO  epoch 9 evaluating [time: 1.02s, valid_score: 0.048900]
11 Feb 23:21    INFO  valid result: 
hit@1 : 0.009    hit@5 : 0.0651    hit@10 : 0.1    hit@20 : 0.1413    ndcg@1 : 0.009    ndcg@5 : 0.0376    ndcg@10 : 0.0489    ndcg@20 : 0.0593    mrr@1 : 0.009    mrr@5 : 0.0286    mrr@10 : 0.0332    mrr@20 : 0.036
11 Feb 23:23    INFO  epoch 10 training [time: 69.17s, train loss: 6821.7233]
11 Feb 23:23    INFO  epoch 10 evaluating [time: 1.03s, valid_score: 0.050300]
11 Feb 23:23    INFO  valid result: 
hit@1 : 0.0101    hit@5 : 0.0673    hit@10 : 0.101    hit@20 : 0.1416    ndcg@1 : 0.0101    ndcg@5 : 0.0394    ndcg@10 : 0.0503    ndcg@20 : 0.0605    mrr@1 : 0.0101    mrr@5 : 0.0303    mrr@10 : 0.0348    mrr@20 : 0.0375
11 Feb 23:23    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:24    INFO  epoch 11 training [time: 68.94s, train loss: 6778.8823]
11 Feb 23:24    INFO  epoch 11 evaluating [time: 1.02s, valid_score: 0.050900]
11 Feb 23:24    INFO  valid result: 
hit@1 : 0.0106    hit@5 : 0.0673    hit@10 : 0.1018    hit@20 : 0.1452    ndcg@1 : 0.0106    ndcg@5 : 0.0397    ndcg@10 : 0.0509    ndcg@20 : 0.0618    mrr@1 : 0.0106    mrr@5 : 0.0306    mrr@10 : 0.0352    mrr@20 : 0.0382
11 Feb 23:24    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:25    INFO  epoch 12 training [time: 68.89s, train loss: 6742.4800]
11 Feb 23:25    INFO  epoch 12 evaluating [time: 1.02s, valid_score: 0.050600]
11 Feb 23:25    INFO  valid result: 
hit@1 : 0.0098    hit@5 : 0.0683    hit@10 : 0.1023    hit@20 : 0.1438    ndcg@1 : 0.0098    ndcg@5 : 0.0396    ndcg@10 : 0.0506    ndcg@20 : 0.0611    mrr@1 : 0.0098    mrr@5 : 0.0302    mrr@10 : 0.0348    mrr@20 : 0.0376
11 Feb 23:26    INFO  epoch 13 training [time: 68.88s, train loss: 6707.8455]
11 Feb 23:26    INFO  epoch 13 evaluating [time: 1.02s, valid_score: 0.050300]
11 Feb 23:26    INFO  valid result: 
hit@1 : 0.0097    hit@5 : 0.0682    hit@10 : 0.1017    hit@20 : 0.1429    ndcg@1 : 0.0097    ndcg@5 : 0.0395    ndcg@10 : 0.0503    ndcg@20 : 0.0607    mrr@1 : 0.0097    mrr@5 : 0.03    mrr@10 : 0.0345    mrr@20 : 0.0373
11 Feb 23:27    INFO  epoch 14 training [time: 69.10s, train loss: 6680.5616]
11 Feb 23:27    INFO  epoch 14 evaluating [time: 1.02s, valid_score: 0.051100]
11 Feb 23:27    INFO  valid result: 
hit@1 : 0.0103    hit@5 : 0.0658    hit@10 : 0.1032    hit@20 : 0.1454    ndcg@1 : 0.0103    ndcg@5 : 0.039    ndcg@10 : 0.0511    ndcg@20 : 0.0617    mrr@1 : 0.0103    mrr@5 : 0.0302    mrr@10 : 0.0351    mrr@20 : 0.038
11 Feb 23:27    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:28    INFO  epoch 15 training [time: 69.21s, train loss: 6651.7105]
11 Feb 23:28    INFO  epoch 15 evaluating [time: 1.02s, valid_score: 0.050400]
11 Feb 23:28    INFO  valid result: 
hit@1 : 0.0104    hit@5 : 0.0658    hit@10 : 0.1016    hit@20 : 0.1428    ndcg@1 : 0.0104    ndcg@5 : 0.0389    ndcg@10 : 0.0504    ndcg@20 : 0.0608    mrr@1 : 0.0104    mrr@5 : 0.03    mrr@10 : 0.0348    mrr@20 : 0.0376
11 Feb 23:30    INFO  epoch 16 training [time: 69.06s, train loss: 6621.4162]
11 Feb 23:30    INFO  epoch 16 evaluating [time: 1.02s, valid_score: 0.051000]
11 Feb 23:30    INFO  valid result: 
hit@1 : 0.0095    hit@5 : 0.068    hit@10 : 0.1033    hit@20 : 0.1437    ndcg@1 : 0.0095    ndcg@5 : 0.0396    ndcg@10 : 0.051    ndcg@20 : 0.0612    mrr@1 : 0.0095    mrr@5 : 0.0302    mrr@10 : 0.035    mrr@20 : 0.0377
11 Feb 23:31    INFO  epoch 17 training [time: 69.28s, train loss: 6606.4373]
11 Feb 23:31    INFO  epoch 17 evaluating [time: 1.01s, valid_score: 0.051100]
11 Feb 23:31    INFO  valid result: 
hit@1 : 0.0111    hit@5 : 0.0663    hit@10 : 0.1028    hit@20 : 0.1439    ndcg@1 : 0.0111    ndcg@5 : 0.0393    ndcg@10 : 0.0511    ndcg@20 : 0.0615    mrr@1 : 0.0111    mrr@5 : 0.0305    mrr@10 : 0.0353    mrr@20 : 0.0382
11 Feb 23:31    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:32    INFO  epoch 18 training [time: 68.94s, train loss: 6580.9801]
11 Feb 23:32    INFO  epoch 18 evaluating [time: 1.02s, valid_score: 0.051800]
11 Feb 23:32    INFO  valid result: 
hit@1 : 0.0108    hit@5 : 0.0678    hit@10 : 0.1038    hit@20 : 0.1452    ndcg@1 : 0.0108    ndcg@5 : 0.0401    ndcg@10 : 0.0518    ndcg@20 : 0.0622    mrr@1 : 0.0108    mrr@5 : 0.031    mrr@10 : 0.0358    mrr@20 : 0.0386
11 Feb 23:32    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:33    INFO  epoch 19 training [time: 68.90s, train loss: 6561.2837]
11 Feb 23:33    INFO  epoch 19 evaluating [time: 1.02s, valid_score: 0.051300]
11 Feb 23:33    INFO  valid result: 
hit@1 : 0.0101    hit@5 : 0.0698    hit@10 : 0.1022    hit@20 : 0.1427    ndcg@1 : 0.0101    ndcg@5 : 0.0408    ndcg@10 : 0.0513    ndcg@20 : 0.0615    mrr@1 : 0.0101    mrr@5 : 0.0313    mrr@10 : 0.0356    mrr@20 : 0.0384
11 Feb 23:34    INFO  epoch 20 training [time: 68.73s, train loss: 6546.3498]
11 Feb 23:34    INFO  epoch 20 evaluating [time: 1.02s, valid_score: 0.052200]
11 Feb 23:34    INFO  valid result: 
hit@1 : 0.0114    hit@5 : 0.0697    hit@10 : 0.1041    hit@20 : 0.1453    ndcg@1 : 0.0114    ndcg@5 : 0.0411    ndcg@10 : 0.0522    ndcg@20 : 0.0625    mrr@1 : 0.0114    mrr@5 : 0.0317    mrr@10 : 0.0362    mrr@20 : 0.0391
11 Feb 23:34    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:35    INFO  epoch 21 training [time: 67.38s, train loss: 6527.8202]
11 Feb 23:35    INFO  epoch 21 evaluating [time: 1.01s, valid_score: 0.051900]
11 Feb 23:35    INFO  valid result: 
hit@1 : 0.0099    hit@5 : 0.0698    hit@10 : 0.1045    hit@20 : 0.1466    ndcg@1 : 0.0099    ndcg@5 : 0.0407    ndcg@10 : 0.0519    ndcg@20 : 0.0625    mrr@1 : 0.0099    mrr@5 : 0.0311    mrr@10 : 0.0357    mrr@20 : 0.0386
11 Feb 23:37    INFO  epoch 22 training [time: 67.31s, train loss: 6517.7381]
11 Feb 23:37    INFO  epoch 22 evaluating [time: 1.02s, valid_score: 0.051700]
11 Feb 23:37    INFO  valid result: 
hit@1 : 0.0102    hit@5 : 0.0693    hit@10 : 0.1044    hit@20 : 0.1457    ndcg@1 : 0.0102    ndcg@5 : 0.0405    ndcg@10 : 0.0517    ndcg@20 : 0.0622    mrr@1 : 0.0102    mrr@5 : 0.031    mrr@10 : 0.0356    mrr@20 : 0.0385
11 Feb 23:38    INFO  epoch 23 training [time: 67.37s, train loss: 6497.0817]
11 Feb 23:38    INFO  epoch 23 evaluating [time: 1.03s, valid_score: 0.051700]
11 Feb 23:38    INFO  valid result: 
hit@1 : 0.0104    hit@5 : 0.0687    hit@10 : 0.104    hit@20 : 0.1452    ndcg@1 : 0.0104    ndcg@5 : 0.0403    ndcg@10 : 0.0517    ndcg@20 : 0.0621    mrr@1 : 0.0104    mrr@5 : 0.0309    mrr@10 : 0.0356    mrr@20 : 0.0385
11 Feb 23:39    INFO  epoch 24 training [time: 67.49s, train loss: 6489.5682]
11 Feb 23:39    INFO  epoch 24 evaluating [time: 1.02s, valid_score: 0.052400]
11 Feb 23:39    INFO  valid result: 
hit@1 : 0.0115    hit@5 : 0.0695    hit@10 : 0.1036    hit@20 : 0.1459    ndcg@1 : 0.0115    ndcg@5 : 0.0414    ndcg@10 : 0.0524    ndcg@20 : 0.063    mrr@1 : 0.0115    mrr@5 : 0.0322    mrr@10 : 0.0366    mrr@20 : 0.0396
11 Feb 23:39    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:40    INFO  epoch 25 training [time: 67.33s, train loss: 6473.6194]
11 Feb 23:40    INFO  epoch 25 evaluating [time: 1.02s, valid_score: 0.051700]
11 Feb 23:40    INFO  valid result: 
hit@1 : 0.0107    hit@5 : 0.0679    hit@10 : 0.1043    hit@20 : 0.1449    ndcg@1 : 0.0107    ndcg@5 : 0.04    ndcg@10 : 0.0517    ndcg@20 : 0.062    mrr@1 : 0.0107    mrr@5 : 0.0308    mrr@10 : 0.0356    mrr@20 : 0.0384
11 Feb 23:41    INFO  epoch 26 training [time: 67.28s, train loss: 6465.3130]
11 Feb 23:41    INFO  epoch 26 evaluating [time: 1.03s, valid_score: 0.052300]
11 Feb 23:41    INFO  valid result: 
hit@1 : 0.011    hit@5 : 0.0699    hit@10 : 0.1047    hit@20 : 0.1463    ndcg@1 : 0.011    ndcg@5 : 0.0411    ndcg@10 : 0.0523    ndcg@20 : 0.0628    mrr@1 : 0.011    mrr@5 : 0.0316    mrr@10 : 0.0362    mrr@20 : 0.0391
11 Feb 23:42    INFO  epoch 27 training [time: 67.30s, train loss: 6451.6978]
11 Feb 23:42    INFO  epoch 27 evaluating [time: 1.02s, valid_score: 0.053400]
11 Feb 23:42    INFO  valid result: 
hit@1 : 0.0122    hit@5 : 0.071    hit@10 : 0.106    hit@20 : 0.1487    ndcg@1 : 0.0122    ndcg@5 : 0.0422    ndcg@10 : 0.0534    ndcg@20 : 0.0642    mrr@1 : 0.0122    mrr@5 : 0.0327    mrr@10 : 0.0373    mrr@20 : 0.0402
11 Feb 23:42    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:43    INFO  epoch 28 training [time: 67.31s, train loss: 6436.8896]
11 Feb 23:43    INFO  epoch 28 evaluating [time: 1.02s, valid_score: 0.053300]
11 Feb 23:43    INFO  valid result: 
hit@1 : 0.0124    hit@5 : 0.0696    hit@10 : 0.105    hit@20 : 0.1468    ndcg@1 : 0.0124    ndcg@5 : 0.0419    ndcg@10 : 0.0533    ndcg@20 : 0.0638    mrr@1 : 0.0124    mrr@5 : 0.0327    mrr@10 : 0.0374    mrr@20 : 0.0403
11 Feb 23:45    INFO  epoch 29 training [time: 67.38s, train loss: 6429.6261]
11 Feb 23:45    INFO  epoch 29 evaluating [time: 1.03s, valid_score: 0.051600]
11 Feb 23:45    INFO  valid result: 
hit@1 : 0.0107    hit@5 : 0.0681    hit@10 : 0.1035    hit@20 : 0.1467    ndcg@1 : 0.0107    ndcg@5 : 0.0402    ndcg@10 : 0.0516    ndcg@20 : 0.0625    mrr@1 : 0.0107    mrr@5 : 0.031    mrr@10 : 0.0357    mrr@20 : 0.0387
11 Feb 23:46    INFO  epoch 30 training [time: 67.27s, train loss: 6417.7124]
11 Feb 23:46    INFO  epoch 30 evaluating [time: 1.02s, valid_score: 0.053000]
11 Feb 23:46    INFO  valid result: 
hit@1 : 0.0118    hit@5 : 0.0699    hit@10 : 0.1056    hit@20 : 0.1482    ndcg@1 : 0.0118    ndcg@5 : 0.0415    ndcg@10 : 0.053    ndcg@20 : 0.0638    mrr@1 : 0.0118    mrr@5 : 0.0322    mrr@10 : 0.037    mrr@20 : 0.0399
11 Feb 23:47    INFO  epoch 31 training [time: 67.32s, train loss: 6415.6434]
11 Feb 23:47    INFO  epoch 31 evaluating [time: 1.02s, valid_score: 0.052500]
11 Feb 23:47    INFO  valid result: 
hit@1 : 0.0111    hit@5 : 0.07    hit@10 : 0.1047    hit@20 : 0.1484    ndcg@1 : 0.0111    ndcg@5 : 0.0413    ndcg@10 : 0.0525    ndcg@20 : 0.0635    mrr@1 : 0.0111    mrr@5 : 0.0319    mrr@10 : 0.0364    mrr@20 : 0.0395
11 Feb 23:48    INFO  epoch 32 training [time: 67.99s, train loss: 6399.5906]
11 Feb 23:48    INFO  epoch 32 evaluating [time: 1.03s, valid_score: 0.052700]
11 Feb 23:48    INFO  valid result: 
hit@1 : 0.0105    hit@5 : 0.0712    hit@10 : 0.1051    hit@20 : 0.1471    ndcg@1 : 0.0105    ndcg@5 : 0.0417    ndcg@10 : 0.0527    ndcg@20 : 0.0633    mrr@1 : 0.0105    mrr@5 : 0.032    mrr@10 : 0.0366    mrr@20 : 0.0395
11 Feb 23:49    INFO  epoch 33 training [time: 68.89s, train loss: 6393.7828]
11 Feb 23:49    INFO  epoch 33 evaluating [time: 1.03s, valid_score: 0.052700]
11 Feb 23:49    INFO  valid result: 
hit@1 : 0.0113    hit@5 : 0.071    hit@10 : 0.1045    hit@20 : 0.148    ndcg@1 : 0.0113    ndcg@5 : 0.0419    ndcg@10 : 0.0527    ndcg@20 : 0.0636    mrr@1 : 0.0113    mrr@5 : 0.0323    mrr@10 : 0.0367    mrr@20 : 0.0397
11 Feb 23:50    INFO  epoch 34 training [time: 68.91s, train loss: 6388.7402]
11 Feb 23:50    INFO  epoch 34 evaluating [time: 1.02s, valid_score: 0.052200]
11 Feb 23:50    INFO  valid result: 
hit@1 : 0.0111    hit@5 : 0.0687    hit@10 : 0.1038    hit@20 : 0.1469    ndcg@1 : 0.0111    ndcg@5 : 0.0408    ndcg@10 : 0.0522    ndcg@20 : 0.0631    mrr@1 : 0.0111    mrr@5 : 0.0317    mrr@10 : 0.0363    mrr@20 : 0.0393
11 Feb 23:51    INFO  epoch 35 training [time: 68.97s, train loss: 6379.7058]
11 Feb 23:51    INFO  epoch 35 evaluating [time: 1.03s, valid_score: 0.053000]
11 Feb 23:51    INFO  valid result: 
hit@1 : 0.0119    hit@5 : 0.0715    hit@10 : 0.1045    hit@20 : 0.149    ndcg@1 : 0.0119    ndcg@5 : 0.0423    ndcg@10 : 0.053    ndcg@20 : 0.0642    mrr@1 : 0.0119    mrr@5 : 0.0327    mrr@10 : 0.0371    mrr@20 : 0.0402
11 Feb 23:53    INFO  epoch 36 training [time: 68.95s, train loss: 6368.7236]
11 Feb 23:53    INFO  epoch 36 evaluating [time: 1.03s, valid_score: 0.053400]
11 Feb 23:53    INFO  valid result: 
hit@1 : 0.0122    hit@5 : 0.0702    hit@10 : 0.1054    hit@20 : 0.1481    ndcg@1 : 0.0122    ndcg@5 : 0.042    ndcg@10 : 0.0534    ndcg@20 : 0.0641    mrr@1 : 0.0122    mrr@5 : 0.0327    mrr@10 : 0.0374    mrr@20 : 0.0403
11 Feb 23:53    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:54    INFO  epoch 37 training [time: 68.98s, train loss: 6357.9820]
11 Feb 23:54    INFO  epoch 37 evaluating [time: 1.03s, valid_score: 0.052300]
11 Feb 23:54    INFO  valid result: 
hit@1 : 0.0109    hit@5 : 0.0688    hit@10 : 0.1043    hit@20 : 0.1485    ndcg@1 : 0.0109    ndcg@5 : 0.0407    ndcg@10 : 0.0523    ndcg@20 : 0.0634    mrr@1 : 0.0109    mrr@5 : 0.0315    mrr@10 : 0.0363    mrr@20 : 0.0393
11 Feb 23:55    INFO  epoch 38 training [time: 69.00s, train loss: 6352.9472]
11 Feb 23:55    INFO  epoch 38 evaluating [time: 1.02s, valid_score: 0.053800]
11 Feb 23:55    INFO  valid result: 
hit@1 : 0.0118    hit@5 : 0.0697    hit@10 : 0.107    hit@20 : 0.1463    ndcg@1 : 0.0118    ndcg@5 : 0.0418    ndcg@10 : 0.0538    ndcg@20 : 0.0638    mrr@1 : 0.0118    mrr@5 : 0.0326    mrr@10 : 0.0376    mrr@20 : 0.0403
11 Feb 23:55    INFO  Saving current: outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
11 Feb 23:56    INFO  epoch 39 training [time: 68.91s, train loss: 6348.3383]
11 Feb 23:56    INFO  epoch 39 evaluating [time: 1.03s, valid_score: 0.053200]
11 Feb 23:56    INFO  valid result: 
hit@1 : 0.0125    hit@5 : 0.07    hit@10 : 0.1047    hit@20 : 0.1482    ndcg@1 : 0.0125    ndcg@5 : 0.042    ndcg@10 : 0.0532    ndcg@20 : 0.0641    mrr@1 : 0.0125    mrr@5 : 0.0328    mrr@10 : 0.0374    mrr@20 : 0.0404
11 Feb 23:57    INFO  epoch 40 training [time: 68.91s, train loss: 6341.2389]
11 Feb 23:57    INFO  epoch 40 evaluating [time: 1.03s, valid_score: 0.053100]
11 Feb 23:57    INFO  valid result: 
hit@1 : 0.0118    hit@5 : 0.07    hit@10 : 0.1048    hit@20 : 0.1484    ndcg@1 : 0.0118    ndcg@5 : 0.0419    ndcg@10 : 0.0531    ndcg@20 : 0.0641    mrr@1 : 0.0118    mrr@5 : 0.0326    mrr@10 : 0.0372    mrr@20 : 0.0402
11 Feb 23:58    INFO  epoch 41 training [time: 68.90s, train loss: 6333.1680]
11 Feb 23:58    INFO  epoch 41 evaluating [time: 1.03s, valid_score: 0.052500]
11 Feb 23:58    INFO  valid result: 
hit@1 : 0.0118    hit@5 : 0.0686    hit@10 : 0.1037    hit@20 : 0.1435    ndcg@1 : 0.0118    ndcg@5 : 0.0412    ndcg@10 : 0.0525    ndcg@20 : 0.0626    mrr@1 : 0.0118    mrr@5 : 0.0322    mrr@10 : 0.0368    mrr@20 : 0.0396
12 Feb 00:00    INFO  epoch 42 training [time: 68.90s, train loss: 6324.1128]
12 Feb 00:00    INFO  epoch 42 evaluating [time: 1.03s, valid_score: 0.053300]
12 Feb 00:00    INFO  valid result: 
hit@1 : 0.0129    hit@5 : 0.0701    hit@10 : 0.1043    hit@20 : 0.1475    ndcg@1 : 0.0129    ndcg@5 : 0.0423    ndcg@10 : 0.0533    ndcg@20 : 0.0642    mrr@1 : 0.0129    mrr@5 : 0.0332    mrr@10 : 0.0377    mrr@20 : 0.0407
12 Feb 00:01    INFO  epoch 43 training [time: 68.88s, train loss: 6321.1278]
12 Feb 00:01    INFO  epoch 43 evaluating [time: 1.05s, valid_score: 0.052300]
12 Feb 00:01    INFO  valid result: 
hit@1 : 0.0114    hit@5 : 0.0707    hit@10 : 0.1044    hit@20 : 0.1469    ndcg@1 : 0.0114    ndcg@5 : 0.0415    ndcg@10 : 0.0523    ndcg@20 : 0.063    mrr@1 : 0.0114    mrr@5 : 0.0319    mrr@10 : 0.0363    mrr@20 : 0.0392
12 Feb 00:02    INFO  epoch 44 training [time: 68.98s, train loss: 6317.2119]
12 Feb 00:02    INFO  epoch 44 evaluating [time: 1.06s, valid_score: 0.053400]
12 Feb 00:02    INFO  valid result: 
hit@1 : 0.0111    hit@5 : 0.0722    hit@10 : 0.1062    hit@20 : 0.149    ndcg@1 : 0.0111    ndcg@5 : 0.0424    ndcg@10 : 0.0534    ndcg@20 : 0.0641    mrr@1 : 0.0111    mrr@5 : 0.0326    mrr@10 : 0.0371    mrr@20 : 0.04
12 Feb 00:03    INFO  epoch 45 training [time: 68.98s, train loss: 6314.6884]
12 Feb 00:03    INFO  epoch 45 evaluating [time: 1.04s, valid_score: 0.053100]
12 Feb 00:03    INFO  valid result: 
hit@1 : 0.0123    hit@5 : 0.0697    hit@10 : 0.105    hit@20 : 0.1466    ndcg@1 : 0.0123    ndcg@5 : 0.0417    ndcg@10 : 0.0531    ndcg@20 : 0.0636    mrr@1 : 0.0123    mrr@5 : 0.0325    mrr@10 : 0.0372    mrr@20 : 0.0401
12 Feb 00:04    INFO  epoch 46 training [time: 68.96s, train loss: 6300.3074]
12 Feb 00:04    INFO  epoch 46 evaluating [time: 1.05s, valid_score: 0.053100]
12 Feb 00:04    INFO  valid result: 
hit@1 : 0.0121    hit@5 : 0.0702    hit@10 : 0.1053    hit@20 : 0.148    ndcg@1 : 0.0121    ndcg@5 : 0.0417    ndcg@10 : 0.0531    ndcg@20 : 0.0638    mrr@1 : 0.0121    mrr@5 : 0.0324    mrr@10 : 0.037    mrr@20 : 0.04
12 Feb 00:05    INFO  epoch 47 training [time: 68.93s, train loss: 6303.6081]
12 Feb 00:05    INFO  epoch 47 evaluating [time: 1.05s, valid_score: 0.052700]
12 Feb 00:05    INFO  valid result: 
hit@1 : 0.0123    hit@5 : 0.0697    hit@10 : 0.1034    hit@20 : 0.1469    ndcg@1 : 0.0123    ndcg@5 : 0.0418    ndcg@10 : 0.0527    ndcg@20 : 0.0636    mrr@1 : 0.0123    mrr@5 : 0.0326    mrr@10 : 0.0371    mrr@20 : 0.0401
12 Feb 00:07    INFO  epoch 48 training [time: 68.92s, train loss: 6292.8607]
12 Feb 00:07    INFO  epoch 48 evaluating [time: 1.06s, valid_score: 0.052900]
12 Feb 00:07    INFO  valid result: 
hit@1 : 0.011    hit@5 : 0.071    hit@10 : 0.105    hit@20 : 0.1487    ndcg@1 : 0.011    ndcg@5 : 0.0419    ndcg@10 : 0.0529    ndcg@20 : 0.0639    mrr@1 : 0.011    mrr@5 : 0.0323    mrr@10 : 0.0368    mrr@20 : 0.0398
12 Feb 00:08    INFO  epoch 49 training [time: 68.97s, train loss: 6286.5519]
12 Feb 00:08    INFO  epoch 49 evaluating [time: 1.05s, valid_score: 0.052700]
12 Feb 00:08    INFO  valid result: 
hit@1 : 0.0115    hit@5 : 0.0702    hit@10 : 0.1046    hit@20 : 0.1469    ndcg@1 : 0.0115    ndcg@5 : 0.0416    ndcg@10 : 0.0527    ndcg@20 : 0.0634    mrr@1 : 0.0115    mrr@5 : 0.0322    mrr@10 : 0.0368    mrr@20 : 0.0397
12 Feb 00:08    INFO  Finished training, best eval result in epoch 38
12 Feb 00:08    INFO  Loading model structure and parameters from outputs/fearec_beauty/FEARec-Feb-11-2026_23-10-13.pth
12 Feb 00:08    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      3.30 %      |
+-------------+------------------+
| GPU         |  3.01 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.60 G/2015.66 G |
+-------------+------------------+
12 Feb 00:08    INFO  best valid : OrderedDict([('hit@1', 0.0118), ('hit@5', 0.0697), ('hit@10', 0.107), ('hit@20', 0.1463), ('ndcg@1', 0.0118), ('ndcg@5', 0.0418), ('ndcg@10', 0.0538), ('ndcg@20', 0.0638), ('mrr@1', 0.0118), ('mrr@5', 0.0326), ('mrr@10', 0.0376), ('mrr@20', 0.0403)])
12 Feb 00:08    INFO  test result: OrderedDict([('hit@1', 0.0102), ('hit@5', 0.0573), ('hit@10', 0.0854), ('hit@20', 0.1208), ('ndcg@1', 0.0102), ('ndcg@5', 0.0343), ('ndcg@10', 0.0433), ('ndcg@20', 0.0522), ('mrr@1', 0.0102), ('mrr@5', 0.0267), ('mrr@10', 0.0304), ('mrr@20', 0.0328)])
Job completed.

======================================================================================
                  Resource Usage on 2026-02-12 00:08:24:
   Job Id:             160692432.gadi-pbs
   Project:            up63
   Exit Status:        0
   Service Units:      70.48
   NCPUs Requested:    16                  CPU Time Used: 00:58:36        
   Memory Requested:   16.0GB                Memory Used: 1.45GB          
   NGPUs Requested:    1                 GPU Utilisation: 12%             
                                         GPU Memory Used: 3.52GB          
   Walltime Requested: 04:00:00            Walltime Used: 00:58:44        
   JobFS Requested:    100.0MB                JobFS Used: 5.03KB          
======================================================================================
