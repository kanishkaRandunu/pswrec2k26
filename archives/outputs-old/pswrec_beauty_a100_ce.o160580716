=== hostname ===
gadi-dgx-a100-0002.gadi.nci.org.au
=== PBS_JOBID ===
160580716.gadi-pbs
command line args [-m PSWRec -d amazon-beauty --config_files configs/beauty/beauty_PSWRec_A100_CE.yaml] will not be used in RecBole
10 Feb 20:30    INFO  ['RecBole/run_recbole.py', '-m', 'PSWRec', '-d', 'amazon-beauty', '--config_files', 'configs/beauty/beauty_PSWRec_A100_CE.yaml']
10 Feb 20:30    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2026
state = INFO
reproducibility = True
data_path = /scratch/up63/kd6504/recbole_datasets/amazon-beauty
checkpoint_dir = outputs/pswrec_beauty_a100_ce
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Hit', 'NDCG', 'MRR', 'Recall']
topk = [10]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = {'inter': ['rating']}
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [5,inf)
item_inter_num_interval = [5,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
n_bands = 4
band_kernel_sizes = [3, 7, 15, 31]
band_dilations = [1, 1, 2, 4]
phase_bias_scale = 0.1
phase_aux = False
phase_aux_weight = 0.0
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:648: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=0, inplace=True)
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:650: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.
Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.

See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html
  feat[field].fillna(value=feat[field].mean(), inplace=True)
10 Feb 20:30    INFO  amazon-beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
/home/572/kd6504/TRACT/RecBole/recbole/data/dataset/dataset.py:2202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  new_data[k] = torch.LongTensor(value)
10 Feb 20:30    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
10 Feb 20:30    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
10 Feb 20:30    INFO  PSWRec(
  (item_embedding): Embedding(12102, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (phase_filter): LocalPhaseFilterBank(
    (real_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(14,), dilation=(2,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(60,), dilation=(4,), groups=64, bias=False)
    )
    (imag_convs): ModuleList(
      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64, bias=False)
      (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), groups=64, bias=False)
      (2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(14,), dilation=(2,), groups=64, bias=False)
      (3): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(60,), dilation=(4,), groups=64, bias=False)
    )
  )
  (encoder): PSWEncoder(
    (layers): ModuleList(
      (0-1): 2 x PSWBlock(
        (attn): PhaseSyncAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (out_proj): Linear(in_features=64, out_features=64, bias=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        )
        (ffn): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (layer_norm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 885012
10 Feb 20:30    INFO  FLOPs: 5312064.0
/home/572/kd6504/TRACT/RecBole/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
10 Feb 20:31    INFO  epoch 0 training [time: 56.94s, train loss: 8843.3062]
10 Feb 20:31    INFO  epoch 0 evaluating [time: 0.48s, valid_score: 0.019300]
10 Feb 20:31    INFO  valid result: 
hit@10 : 0.0397    ndcg@10 : 0.0193    mrr@10 : 0.0133    recall@10 : 0.0397
10 Feb 20:31    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:32    INFO  epoch 1 training [time: 55.91s, train loss: 8195.4029]
10 Feb 20:32    INFO  epoch 1 evaluating [time: 0.30s, valid_score: 0.029400]
10 Feb 20:32    INFO  valid result: 
hit@10 : 0.0558    ndcg@10 : 0.0294    mrr@10 : 0.0214    recall@10 : 0.0558
10 Feb 20:32    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:33    INFO  epoch 2 training [time: 55.91s, train loss: 7897.4119]
10 Feb 20:33    INFO  epoch 2 evaluating [time: 0.29s, valid_score: 0.035800]
10 Feb 20:33    INFO  valid result: 
hit@10 : 0.0704    ndcg@10 : 0.0358    mrr@10 : 0.0254    recall@10 : 0.0704
10 Feb 20:33    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:34    INFO  epoch 3 training [time: 55.90s, train loss: 7669.7333]
10 Feb 20:34    INFO  epoch 3 evaluating [time: 0.29s, valid_score: 0.041500]
10 Feb 20:34    INFO  valid result: 
hit@10 : 0.0823    ndcg@10 : 0.0415    mrr@10 : 0.0291    recall@10 : 0.0823
10 Feb 20:34    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:35    INFO  epoch 4 training [time: 55.91s, train loss: 7479.3858]
10 Feb 20:35    INFO  epoch 4 evaluating [time: 0.29s, valid_score: 0.044900]
10 Feb 20:35    INFO  valid result: 
hit@10 : 0.0891    ndcg@10 : 0.0449    mrr@10 : 0.0314    recall@10 : 0.0891
10 Feb 20:35    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:36    INFO  epoch 5 training [time: 55.89s, train loss: 7326.7718]
10 Feb 20:36    INFO  epoch 5 evaluating [time: 0.29s, valid_score: 0.047400]
10 Feb 20:36    INFO  valid result: 
hit@10 : 0.0941    ndcg@10 : 0.0474    mrr@10 : 0.0331    recall@10 : 0.0941
10 Feb 20:36    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:37    INFO  epoch 6 training [time: 55.90s, train loss: 7192.4898]
10 Feb 20:37    INFO  epoch 6 evaluating [time: 0.30s, valid_score: 0.047700]
10 Feb 20:37    INFO  valid result: 
hit@10 : 0.0951    ndcg@10 : 0.0477    mrr@10 : 0.0332    recall@10 : 0.0951
10 Feb 20:37    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:38    INFO  epoch 7 training [time: 55.88s, train loss: 7098.6332]
10 Feb 20:38    INFO  epoch 7 evaluating [time: 0.29s, valid_score: 0.048500]
10 Feb 20:38    INFO  valid result: 
hit@10 : 0.0978    ndcg@10 : 0.0485    mrr@10 : 0.0333    recall@10 : 0.0978
10 Feb 20:38    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:39    INFO  epoch 8 training [time: 55.87s, train loss: 7011.7812]
10 Feb 20:39    INFO  epoch 8 evaluating [time: 0.30s, valid_score: 0.048700]
10 Feb 20:39    INFO  valid result: 
hit@10 : 0.0973    ndcg@10 : 0.0487    mrr@10 : 0.0337    recall@10 : 0.0973
10 Feb 20:39    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:40    INFO  epoch 9 training [time: 55.89s, train loss: 6947.1938]
10 Feb 20:40    INFO  epoch 9 evaluating [time: 0.30s, valid_score: 0.049200]
10 Feb 20:40    INFO  valid result: 
hit@10 : 0.0996    ndcg@10 : 0.0492    mrr@10 : 0.0337    recall@10 : 0.0996
10 Feb 20:40    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:41    INFO  epoch 10 training [time: 55.89s, train loss: 6882.2086]
10 Feb 20:41    INFO  epoch 10 evaluating [time: 0.29s, valid_score: 0.049700]
10 Feb 20:41    INFO  valid result: 
hit@10 : 0.0999    ndcg@10 : 0.0497    mrr@10 : 0.0343    recall@10 : 0.0999
10 Feb 20:41    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:42    INFO  epoch 11 training [time: 55.89s, train loss: 6840.9592]
10 Feb 20:42    INFO  epoch 11 evaluating [time: 0.29s, valid_score: 0.051100]
10 Feb 20:42    INFO  valid result: 
hit@10 : 0.1022    ndcg@10 : 0.0511    mrr@10 : 0.0354    recall@10 : 0.1022
10 Feb 20:42    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:43    INFO  epoch 12 training [time: 55.90s, train loss: 6801.2696]
10 Feb 20:43    INFO  epoch 12 evaluating [time: 0.29s, valid_score: 0.050400]
10 Feb 20:43    INFO  valid result: 
hit@10 : 0.1017    ndcg@10 : 0.0504    mrr@10 : 0.0347    recall@10 : 0.1017
10 Feb 20:44    INFO  epoch 13 training [time: 55.90s, train loss: 6757.6631]
10 Feb 20:44    INFO  epoch 13 evaluating [time: 0.30s, valid_score: 0.049900]
10 Feb 20:44    INFO  valid result: 
hit@10 : 0.1006    ndcg@10 : 0.0499    mrr@10 : 0.0344    recall@10 : 0.1006
10 Feb 20:45    INFO  epoch 14 training [time: 55.91s, train loss: 6731.3051]
10 Feb 20:45    INFO  epoch 14 evaluating [time: 0.29s, valid_score: 0.050300]
10 Feb 20:45    INFO  valid result: 
hit@10 : 0.1011    ndcg@10 : 0.0503    mrr@10 : 0.0346    recall@10 : 0.1011
10 Feb 20:46    INFO  epoch 15 training [time: 55.99s, train loss: 6704.4540]
10 Feb 20:46    INFO  epoch 15 evaluating [time: 0.29s, valid_score: 0.049700]
10 Feb 20:46    INFO  valid result: 
hit@10 : 0.1008    ndcg@10 : 0.0497    mrr@10 : 0.034    recall@10 : 0.1008
10 Feb 20:46    INFO  epoch 16 training [time: 55.95s, train loss: 6679.0987]
10 Feb 20:46    INFO  epoch 16 evaluating [time: 0.29s, valid_score: 0.050700]
10 Feb 20:46    INFO  valid result: 
hit@10 : 0.1022    ndcg@10 : 0.0507    mrr@10 : 0.0348    recall@10 : 0.1022
10 Feb 20:47    INFO  epoch 17 training [time: 56.01s, train loss: 6658.7410]
10 Feb 20:47    INFO  epoch 17 evaluating [time: 0.29s, valid_score: 0.050300]
10 Feb 20:47    INFO  valid result: 
hit@10 : 0.1012    ndcg@10 : 0.0503    mrr@10 : 0.0347    recall@10 : 0.1012
10 Feb 20:48    INFO  epoch 18 training [time: 55.91s, train loss: 6634.9639]
10 Feb 20:48    INFO  epoch 18 evaluating [time: 0.30s, valid_score: 0.051300]
10 Feb 20:48    INFO  valid result: 
hit@10 : 0.1007    ndcg@10 : 0.0513    mrr@10 : 0.0362    recall@10 : 0.1007
10 Feb 20:48    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:49    INFO  epoch 19 training [time: 55.99s, train loss: 6608.1903]
10 Feb 20:49    INFO  epoch 19 evaluating [time: 0.29s, valid_score: 0.050800]
10 Feb 20:49    INFO  valid result: 
hit@10 : 0.1016    ndcg@10 : 0.0508    mrr@10 : 0.0352    recall@10 : 0.1016
10 Feb 20:50    INFO  epoch 20 training [time: 55.95s, train loss: 6596.4753]
10 Feb 20:50    INFO  epoch 20 evaluating [time: 0.29s, valid_score: 0.051500]
10 Feb 20:50    INFO  valid result: 
hit@10 : 0.1022    ndcg@10 : 0.0515    mrr@10 : 0.0359    recall@10 : 0.1022
10 Feb 20:50    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:51    INFO  epoch 21 training [time: 56.76s, train loss: 6583.6806]
10 Feb 20:51    INFO  epoch 21 evaluating [time: 0.51s, valid_score: 0.051200]
10 Feb 20:51    INFO  valid result: 
hit@10 : 0.1024    ndcg@10 : 0.0512    mrr@10 : 0.0355    recall@10 : 0.1024
10 Feb 20:52    INFO  epoch 22 training [time: 56.03s, train loss: 6566.3837]
10 Feb 20:52    INFO  epoch 22 evaluating [time: 0.29s, valid_score: 0.051000]
10 Feb 20:52    INFO  valid result: 
hit@10 : 0.1031    ndcg@10 : 0.051    mrr@10 : 0.035    recall@10 : 0.1031
10 Feb 20:53    INFO  epoch 23 training [time: 56.00s, train loss: 6554.3814]
10 Feb 20:53    INFO  epoch 23 evaluating [time: 0.30s, valid_score: 0.050700]
10 Feb 20:53    INFO  valid result: 
hit@10 : 0.1019    ndcg@10 : 0.0507    mrr@10 : 0.035    recall@10 : 0.1019
10 Feb 20:54    INFO  epoch 24 training [time: 56.02s, train loss: 6535.3478]
10 Feb 20:54    INFO  epoch 24 evaluating [time: 0.29s, valid_score: 0.051600]
10 Feb 20:54    INFO  valid result: 
hit@10 : 0.1029    ndcg@10 : 0.0516    mrr@10 : 0.0358    recall@10 : 0.1029
10 Feb 20:54    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:55    INFO  epoch 25 training [time: 55.94s, train loss: 6528.6911]
10 Feb 20:55    INFO  epoch 25 evaluating [time: 0.29s, valid_score: 0.050900]
10 Feb 20:55    INFO  valid result: 
hit@10 : 0.102    ndcg@10 : 0.0509    mrr@10 : 0.0352    recall@10 : 0.102
10 Feb 20:56    INFO  epoch 26 training [time: 55.94s, train loss: 6508.5864]
10 Feb 20:56    INFO  epoch 26 evaluating [time: 0.30s, valid_score: 0.051600]
10 Feb 20:56    INFO  valid result: 
hit@10 : 0.1017    ndcg@10 : 0.0516    mrr@10 : 0.0362    recall@10 : 0.1017
10 Feb 20:56    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:57    INFO  epoch 27 training [time: 55.98s, train loss: 6503.1891]
10 Feb 20:57    INFO  epoch 27 evaluating [time: 0.29s, valid_score: 0.051700]
10 Feb 20:57    INFO  valid result: 
hit@10 : 0.1032    ndcg@10 : 0.0517    mrr@10 : 0.0359    recall@10 : 0.1032
10 Feb 20:57    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:58    INFO  epoch 28 training [time: 56.10s, train loss: 6493.0597]
10 Feb 20:58    INFO  epoch 28 evaluating [time: 0.29s, valid_score: 0.052100]
10 Feb 20:58    INFO  valid result: 
hit@10 : 0.1032    ndcg@10 : 0.0521    mrr@10 : 0.0364    recall@10 : 0.1032
10 Feb 20:58    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 20:59    INFO  epoch 29 training [time: 55.94s, train loss: 6483.4918]
10 Feb 20:59    INFO  epoch 29 evaluating [time: 0.29s, valid_score: 0.051300]
10 Feb 20:59    INFO  valid result: 
hit@10 : 0.1032    ndcg@10 : 0.0513    mrr@10 : 0.0354    recall@10 : 0.1032
10 Feb 21:00    INFO  epoch 30 training [time: 55.89s, train loss: 6472.2571]
10 Feb 21:00    INFO  epoch 30 evaluating [time: 0.30s, valid_score: 0.051800]
10 Feb 21:00    INFO  valid result: 
hit@10 : 0.1022    ndcg@10 : 0.0518    mrr@10 : 0.0363    recall@10 : 0.1022
10 Feb 21:01    INFO  epoch 31 training [time: 55.98s, train loss: 6461.7093]
10 Feb 21:01    INFO  epoch 31 evaluating [time: 0.29s, valid_score: 0.051000]
10 Feb 21:01    INFO  valid result: 
hit@10 : 0.1018    ndcg@10 : 0.051    mrr@10 : 0.0353    recall@10 : 0.1018
10 Feb 21:01    INFO  epoch 32 training [time: 55.84s, train loss: 6450.6824]
10 Feb 21:01    INFO  epoch 32 evaluating [time: 0.30s, valid_score: 0.052800]
10 Feb 21:01    INFO  valid result: 
hit@10 : 0.1037    ndcg@10 : 0.0528    mrr@10 : 0.0371    recall@10 : 0.1037
10 Feb 21:01    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:02    INFO  epoch 33 training [time: 56.12s, train loss: 6449.4530]
10 Feb 21:02    INFO  epoch 33 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:02    INFO  valid result: 
hit@10 : 0.1041    ndcg@10 : 0.0526    mrr@10 : 0.0368    recall@10 : 0.1041
10 Feb 21:03    INFO  epoch 34 training [time: 55.85s, train loss: 6435.7101]
10 Feb 21:03    INFO  epoch 34 evaluating [time: 0.29s, valid_score: 0.051400]
10 Feb 21:03    INFO  valid result: 
hit@10 : 0.1033    ndcg@10 : 0.0514    mrr@10 : 0.0355    recall@10 : 0.1033
10 Feb 21:04    INFO  epoch 35 training [time: 55.89s, train loss: 6432.4090]
10 Feb 21:04    INFO  epoch 35 evaluating [time: 0.29s, valid_score: 0.052900]
10 Feb 21:04    INFO  valid result: 
hit@10 : 0.1046    ndcg@10 : 0.0529    mrr@10 : 0.037    recall@10 : 0.1046
10 Feb 21:04    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:05    INFO  epoch 36 training [time: 55.89s, train loss: 6421.4454]
10 Feb 21:05    INFO  epoch 36 evaluating [time: 0.29s, valid_score: 0.052100]
10 Feb 21:05    INFO  valid result: 
hit@10 : 0.1042    ndcg@10 : 0.0521    mrr@10 : 0.0361    recall@10 : 0.1042
10 Feb 21:06    INFO  epoch 37 training [time: 55.96s, train loss: 6415.8608]
10 Feb 21:06    INFO  epoch 37 evaluating [time: 0.29s, valid_score: 0.051700]
10 Feb 21:06    INFO  valid result: 
hit@10 : 0.1043    ndcg@10 : 0.0517    mrr@10 : 0.0355    recall@10 : 0.1043
10 Feb 21:07    INFO  epoch 38 training [time: 55.85s, train loss: 6413.6186]
10 Feb 21:07    INFO  epoch 38 evaluating [time: 0.30s, valid_score: 0.052600]
10 Feb 21:07    INFO  valid result: 
hit@10 : 0.1037    ndcg@10 : 0.0526    mrr@10 : 0.0369    recall@10 : 0.1037
10 Feb 21:08    INFO  epoch 39 training [time: 56.02s, train loss: 6402.9875]
10 Feb 21:08    INFO  epoch 39 evaluating [time: 0.29s, valid_score: 0.052100]
10 Feb 21:08    INFO  valid result: 
hit@10 : 0.1031    ndcg@10 : 0.0521    mrr@10 : 0.0365    recall@10 : 0.1031
10 Feb 21:09    INFO  epoch 40 training [time: 56.02s, train loss: 6394.6473]
10 Feb 21:09    INFO  epoch 40 evaluating [time: 0.29s, valid_score: 0.051800]
10 Feb 21:09    INFO  valid result: 
hit@10 : 0.1032    ndcg@10 : 0.0518    mrr@10 : 0.0361    recall@10 : 0.1032
10 Feb 21:10    INFO  epoch 41 training [time: 56.05s, train loss: 6387.3259]
10 Feb 21:10    INFO  epoch 41 evaluating [time: 0.29s, valid_score: 0.052000]
10 Feb 21:10    INFO  valid result: 
hit@10 : 0.1025    ndcg@10 : 0.052    mrr@10 : 0.0365    recall@10 : 0.1025
10 Feb 21:11    INFO  epoch 42 training [time: 55.99s, train loss: 6385.9469]
10 Feb 21:11    INFO  epoch 42 evaluating [time: 0.29s, valid_score: 0.052400]
10 Feb 21:11    INFO  valid result: 
hit@10 : 0.1048    ndcg@10 : 0.0524    mrr@10 : 0.0363    recall@10 : 0.1048
10 Feb 21:12    INFO  epoch 43 training [time: 56.04s, train loss: 6377.3536]
10 Feb 21:12    INFO  epoch 43 evaluating [time: 0.29s, valid_score: 0.052000]
10 Feb 21:12    INFO  valid result: 
hit@10 : 0.1031    ndcg@10 : 0.052    mrr@10 : 0.0362    recall@10 : 0.1031
10 Feb 21:13    INFO  epoch 44 training [time: 56.03s, train loss: 6366.9415]
10 Feb 21:13    INFO  epoch 44 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:13    INFO  valid result: 
hit@10 : 0.1046    ndcg@10 : 0.0526    mrr@10 : 0.0365    recall@10 : 0.1046
10 Feb 21:14    INFO  epoch 45 training [time: 56.05s, train loss: 6363.1610]
10 Feb 21:14    INFO  epoch 45 evaluating [time: 0.29s, valid_score: 0.052800]
10 Feb 21:14    INFO  valid result: 
hit@10 : 0.1045    ndcg@10 : 0.0528    mrr@10 : 0.037    recall@10 : 0.1045
10 Feb 21:15    INFO  epoch 46 training [time: 56.09s, train loss: 6355.4399]
10 Feb 21:15    INFO  epoch 46 evaluating [time: 0.29s, valid_score: 0.052900]
10 Feb 21:15    INFO  valid result: 
hit@10 : 0.1055    ndcg@10 : 0.0529    mrr@10 : 0.0368    recall@10 : 0.1055
10 Feb 21:15    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:16    INFO  epoch 47 training [time: 56.09s, train loss: 6349.8477]
10 Feb 21:16    INFO  epoch 47 evaluating [time: 0.29s, valid_score: 0.051800]
10 Feb 21:16    INFO  valid result: 
hit@10 : 0.1036    ndcg@10 : 0.0518    mrr@10 : 0.036    recall@10 : 0.1036
10 Feb 21:16    INFO  epoch 48 training [time: 55.99s, train loss: 6344.7726]
10 Feb 21:16    INFO  epoch 48 evaluating [time: 0.29s, valid_score: 0.052300]
10 Feb 21:16    INFO  valid result: 
hit@10 : 0.1046    ndcg@10 : 0.0523    mrr@10 : 0.0362    recall@10 : 0.1046
10 Feb 21:17    INFO  epoch 49 training [time: 55.98s, train loss: 6345.6581]
10 Feb 21:17    INFO  epoch 49 evaluating [time: 0.29s, valid_score: 0.052400]
10 Feb 21:17    INFO  valid result: 
hit@10 : 0.1047    ndcg@10 : 0.0524    mrr@10 : 0.0363    recall@10 : 0.1047
10 Feb 21:18    INFO  epoch 50 training [time: 56.01s, train loss: 6339.9523]
10 Feb 21:18    INFO  epoch 50 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:18    INFO  valid result: 
hit@10 : 0.1054    ndcg@10 : 0.0526    mrr@10 : 0.0364    recall@10 : 0.1054
10 Feb 21:19    INFO  epoch 51 training [time: 56.18s, train loss: 6335.4384]
10 Feb 21:19    INFO  epoch 51 evaluating [time: 0.29s, valid_score: 0.051900]
10 Feb 21:19    INFO  valid result: 
hit@10 : 0.1033    ndcg@10 : 0.0519    mrr@10 : 0.0361    recall@10 : 0.1033
10 Feb 21:20    INFO  epoch 52 training [time: 55.98s, train loss: 6330.7994]
10 Feb 21:20    INFO  epoch 52 evaluating [time: 0.29s, valid_score: 0.053100]
10 Feb 21:20    INFO  valid result: 
hit@10 : 0.1049    ndcg@10 : 0.0531    mrr@10 : 0.0372    recall@10 : 0.1049
10 Feb 21:20    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:21    INFO  epoch 53 training [time: 56.05s, train loss: 6328.4317]
10 Feb 21:21    INFO  epoch 53 evaluating [time: 0.29s, valid_score: 0.052700]
10 Feb 21:21    INFO  valid result: 
hit@10 : 0.1057    ndcg@10 : 0.0527    mrr@10 : 0.0365    recall@10 : 0.1057
10 Feb 21:22    INFO  epoch 54 training [time: 56.07s, train loss: 6321.9496]
10 Feb 21:22    INFO  epoch 54 evaluating [time: 0.29s, valid_score: 0.051800]
10 Feb 21:22    INFO  valid result: 
hit@10 : 0.1029    ndcg@10 : 0.0518    mrr@10 : 0.0361    recall@10 : 0.1029
10 Feb 21:23    INFO  epoch 55 training [time: 56.02s, train loss: 6316.4069]
10 Feb 21:23    INFO  epoch 55 evaluating [time: 0.29s, valid_score: 0.053100]
10 Feb 21:23    INFO  valid result: 
hit@10 : 0.1046    ndcg@10 : 0.0531    mrr@10 : 0.0372    recall@10 : 0.1046
10 Feb 21:23    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:24    INFO  epoch 56 training [time: 55.97s, train loss: 6309.0239]
10 Feb 21:24    INFO  epoch 56 evaluating [time: 0.28s, valid_score: 0.052200]
10 Feb 21:24    INFO  valid result: 
hit@10 : 0.1033    ndcg@10 : 0.0522    mrr@10 : 0.0365    recall@10 : 0.1033
10 Feb 21:25    INFO  epoch 57 training [time: 56.04s, train loss: 6301.7986]
10 Feb 21:25    INFO  epoch 57 evaluating [time: 0.29s, valid_score: 0.052500]
10 Feb 21:25    INFO  valid result: 
hit@10 : 0.1053    ndcg@10 : 0.0525    mrr@10 : 0.0363    recall@10 : 0.1053
10 Feb 21:26    INFO  epoch 58 training [time: 56.02s, train loss: 6304.1525]
10 Feb 21:26    INFO  epoch 58 evaluating [time: 0.29s, valid_score: 0.052500]
10 Feb 21:26    INFO  valid result: 
hit@10 : 0.1037    ndcg@10 : 0.0525    mrr@10 : 0.0368    recall@10 : 0.1037
10 Feb 21:27    INFO  epoch 59 training [time: 56.04s, train loss: 6296.0500]
10 Feb 21:27    INFO  epoch 59 evaluating [time: 0.29s, valid_score: 0.052500]
10 Feb 21:27    INFO  valid result: 
hit@10 : 0.105    ndcg@10 : 0.0525    mrr@10 : 0.0364    recall@10 : 0.105
10 Feb 21:28    INFO  epoch 60 training [time: 56.01s, train loss: 6290.9358]
10 Feb 21:28    INFO  epoch 60 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:28    INFO  valid result: 
hit@10 : 0.1046    ndcg@10 : 0.0526    mrr@10 : 0.0366    recall@10 : 0.1046
10 Feb 21:29    INFO  epoch 61 training [time: 56.06s, train loss: 6287.4907]
10 Feb 21:29    INFO  epoch 61 evaluating [time: 0.29s, valid_score: 0.053100]
10 Feb 21:29    INFO  valid result: 
hit@10 : 0.1052    ndcg@10 : 0.0531    mrr@10 : 0.0371    recall@10 : 0.1052
10 Feb 21:29    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:30    INFO  epoch 62 training [time: 56.04s, train loss: 6286.3450]
10 Feb 21:30    INFO  epoch 62 evaluating [time: 0.29s, valid_score: 0.052800]
10 Feb 21:30    INFO  valid result: 
hit@10 : 0.1053    ndcg@10 : 0.0528    mrr@10 : 0.0367    recall@10 : 0.1053
10 Feb 21:31    INFO  epoch 63 training [time: 56.10s, train loss: 6284.9188]
10 Feb 21:31    INFO  epoch 63 evaluating [time: 0.28s, valid_score: 0.052800]
10 Feb 21:31    INFO  valid result: 
hit@10 : 0.1062    ndcg@10 : 0.0528    mrr@10 : 0.0364    recall@10 : 0.1062
10 Feb 21:32    INFO  epoch 64 training [time: 56.12s, train loss: 6287.5947]
10 Feb 21:32    INFO  epoch 64 evaluating [time: 0.29s, valid_score: 0.051600]
10 Feb 21:32    INFO  valid result: 
hit@10 : 0.1034    ndcg@10 : 0.0516    mrr@10 : 0.0357    recall@10 : 0.1034
10 Feb 21:32    INFO  epoch 65 training [time: 56.05s, train loss: 6273.4409]
10 Feb 21:32    INFO  epoch 65 evaluating [time: 0.29s, valid_score: 0.052200]
10 Feb 21:32    INFO  valid result: 
hit@10 : 0.104    ndcg@10 : 0.0522    mrr@10 : 0.0363    recall@10 : 0.104
10 Feb 21:33    INFO  epoch 66 training [time: 56.03s, train loss: 6277.5388]
10 Feb 21:33    INFO  epoch 66 evaluating [time: 0.28s, valid_score: 0.051700]
10 Feb 21:33    INFO  valid result: 
hit@10 : 0.103    ndcg@10 : 0.0517    mrr@10 : 0.0359    recall@10 : 0.103
10 Feb 21:34    INFO  epoch 67 training [time: 56.02s, train loss: 6272.9920]
10 Feb 21:34    INFO  epoch 67 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:34    INFO  valid result: 
hit@10 : 0.1043    ndcg@10 : 0.0526    mrr@10 : 0.0368    recall@10 : 0.1043
10 Feb 21:35    INFO  epoch 68 training [time: 56.00s, train loss: 6266.5306]
10 Feb 21:35    INFO  epoch 68 evaluating [time: 0.29s, valid_score: 0.053200]
10 Feb 21:35    INFO  valid result: 
hit@10 : 0.1044    ndcg@10 : 0.0532    mrr@10 : 0.0374    recall@10 : 0.1044
10 Feb 21:35    INFO  Saving current: outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:36    INFO  epoch 69 training [time: 56.06s, train loss: 6265.3865]
10 Feb 21:36    INFO  epoch 69 evaluating [time: 0.29s, valid_score: 0.052300]
10 Feb 21:36    INFO  valid result: 
hit@10 : 0.1044    ndcg@10 : 0.0523    mrr@10 : 0.0364    recall@10 : 0.1044
10 Feb 21:37    INFO  epoch 70 training [time: 55.88s, train loss: 6259.6084]
10 Feb 21:37    INFO  epoch 70 evaluating [time: 0.28s, valid_score: 0.053000]
10 Feb 21:37    INFO  valid result: 
hit@10 : 0.1045    ndcg@10 : 0.053    mrr@10 : 0.0371    recall@10 : 0.1045
10 Feb 21:38    INFO  epoch 71 training [time: 56.04s, train loss: 6256.4135]
10 Feb 21:38    INFO  epoch 71 evaluating [time: 0.29s, valid_score: 0.051700]
10 Feb 21:38    INFO  valid result: 
hit@10 : 0.1036    ndcg@10 : 0.0517    mrr@10 : 0.0358    recall@10 : 0.1036
10 Feb 21:39    INFO  epoch 72 training [time: 56.15s, train loss: 6253.3548]
10 Feb 21:39    INFO  epoch 72 evaluating [time: 0.28s, valid_score: 0.052900]
10 Feb 21:39    INFO  valid result: 
hit@10 : 0.1051    ndcg@10 : 0.0529    mrr@10 : 0.037    recall@10 : 0.1051
10 Feb 21:40    INFO  epoch 73 training [time: 55.95s, train loss: 6246.7847]
10 Feb 21:40    INFO  epoch 73 evaluating [time: 0.29s, valid_score: 0.052600]
10 Feb 21:40    INFO  valid result: 
hit@10 : 0.1044    ndcg@10 : 0.0526    mrr@10 : 0.0367    recall@10 : 0.1044
10 Feb 21:41    INFO  epoch 74 training [time: 55.95s, train loss: 6242.2346]
10 Feb 21:41    INFO  epoch 74 evaluating [time: 0.30s, valid_score: 0.052900]
10 Feb 21:41    INFO  valid result: 
hit@10 : 0.1053    ndcg@10 : 0.0529    mrr@10 : 0.0369    recall@10 : 0.1053
10 Feb 21:42    INFO  epoch 75 training [time: 56.02s, train loss: 6242.4800]
10 Feb 21:42    INFO  epoch 75 evaluating [time: 0.29s, valid_score: 0.051400]
10 Feb 21:42    INFO  valid result: 
hit@10 : 0.1036    ndcg@10 : 0.0514    mrr@10 : 0.0353    recall@10 : 0.1036
10 Feb 21:43    INFO  epoch 76 training [time: 55.89s, train loss: 6235.6608]
10 Feb 21:43    INFO  epoch 76 evaluating [time: 0.30s, valid_score: 0.051500]
10 Feb 21:43    INFO  valid result: 
hit@10 : 0.1035    ndcg@10 : 0.0515    mrr@10 : 0.0356    recall@10 : 0.1035
10 Feb 21:44    INFO  epoch 77 training [time: 55.99s, train loss: 6235.5357]
10 Feb 21:44    INFO  epoch 77 evaluating [time: 0.29s, valid_score: 0.052000]
10 Feb 21:44    INFO  valid result: 
hit@10 : 0.103    ndcg@10 : 0.052    mrr@10 : 0.0364    recall@10 : 0.103
10 Feb 21:45    INFO  epoch 78 training [time: 55.94s, train loss: 6234.2481]
10 Feb 21:45    INFO  epoch 78 evaluating [time: 0.29s, valid_score: 0.051800]
10 Feb 21:45    INFO  valid result: 
hit@10 : 0.1025    ndcg@10 : 0.0518    mrr@10 : 0.0362    recall@10 : 0.1025
10 Feb 21:46    INFO  epoch 79 training [time: 55.96s, train loss: 6230.2654]
10 Feb 21:46    INFO  epoch 79 evaluating [time: 0.29s, valid_score: 0.052100]
10 Feb 21:46    INFO  valid result: 
hit@10 : 0.1032    ndcg@10 : 0.0521    mrr@10 : 0.0364    recall@10 : 0.1032
10 Feb 21:46    INFO  Finished training, best eval result in epoch 68
10 Feb 21:46    INFO  Loading model structure and parameters from outputs/pswrec_beauty_a100_ce/PSWRec-Feb-10-2026_20-30-57.pth
10 Feb 21:46    INFO  The running environment of this training is as follows:
+-------------+------------------+
| Environment |      Usage       |
+=============+==================+
| CPU         |      1.20 %      |
+-------------+------------------+
| GPU         |  2.34 G/79.44 G  |
+-------------+------------------+
| Memory      | 1.39 G/2015.66 G |
+-------------+------------------+
10 Feb 21:46    INFO  best valid : OrderedDict([('hit@10', 0.1044), ('ndcg@10', 0.0532), ('mrr@10', 0.0374), ('recall@10', 0.1044)])
10 Feb 21:46    INFO  test result: OrderedDict([('hit@10', 0.0833), ('ndcg@10', 0.0424), ('mrr@10', 0.0298), ('recall@10', 0.0833)])
Job completed.

======================================================================================
                  Resource Usage on 2026-02-10 21:46:21:
   Job Id:             160580716.gadi-pbs
   Project:            up63
   Exit Status:        0
   Service Units:      91.08
   NCPUs Requested:    16                  CPU Time Used: 01:15:30        
   Memory Requested:   16.0GB                Memory Used: 2.06GB          
   NGPUs Requested:    1                 GPU Utilisation: 12%             
                                         GPU Memory Used: 2.84GB          
   Walltime Requested: 06:00:00            Walltime Used: 01:15:54        
   JobFS Requested:    100.0MB                JobFS Used: 5.03KB          
======================================================================================
